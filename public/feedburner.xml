<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"><channel><title>The Philosopher Developer</title><description>Dan Tao's blog, The Philosopher Developer</description><link>http://www.philosopherdeveloper.com/</link><item><title>Automating yourself</title><link>http://www.philosopherdeveloper.com/posts/automating-yourself.html</link><description><![CDATA[<p>When my wife and I moved from Philadelphia to San Francisco in 2010, we brought our espresso machine with us.</p>

<figure><img src="/images/espresso_machine_thumb.jpg" alt="Our espresso machine"><figcaption>Our espresso machine</figcaption></figure>

<p>Back in Philly, we’d had a modest kitchen with just enough counter space for the machine. On lazy weekend mornings, I’d often turn it on and prepare us each a latte drink. It was a nice little ritual.</p>

<p>So we brought it to San Francisco with us. But our first apartment, a little studio we rented from a friend of a friend, didn’t have the room for it. So the machine went into storage.</p>

<p>Then in 2011, we moved to our current apartment in the Mission. The espresso machine is back; but we don’t have quite the counter space that we did in Philadelphia, so it’s sitting on a little cart underneath our microwave, unplugged.</p>

<figure><img src="/images/espresso_machine2.jpg" alt="Our espresso machine now"><figcaption>Our espresso machine now</figcaption></figure>

<p>This isn’t terribly inconvenient. To use it, I only need to pick it up and set it somewhere—say, on our table—then put it back when I’m finished. Still, the fact remains: <strong>I haven’t used it once</strong><sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> since moving here.</p>

<p>How strange, that such a small and seemingly insignificant detail could have such a disproportionate impact on our lives! Instead of plugged in and on the counter, the espresso machine is unplugged and a few feet lower. That’s a small change. But now instead of using the machine every week or so, I <em>never</em> use it. That’s a comparatively <em>big</em> change.</p>

<h2 id="our_programmable_selves_1">Our programmable selves</h2>

<p>I’ve pondered this from time to time, and an idea that keeps recurring to me is that <strong>we humans are programmable</strong>. At least to an extent. Simply by recognizing that my internal decision-making circuitry seems to ignore the espresso machine when it’s near the ground but will actually commit to using it when it’s on the counter, I can alter my behavior by changing its location.</p>

<p>It’s a silly example, but I think this is actually a really important point. The distinction here is essentially the difference between <em>manual</em> and <em>automatic</em> processes. We are most effective when we are able to automate the things we do; that much is obvious. But getting software or robots to do all of our grunt work for us isn’t the only kind of automation. I would define<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> automation as the act of replacing any process requiring manual input with one that does not, but yields acceptable (often better) results.</p>

<p>A few years ago, a friend asked me to help him out with an idea for a software product. I offered to help without payment, but he insisted on paying me. He explained that if he paid me, he knew I would force myself to do the work. Otherwise, I might view our agreement as little more than me doing him a favor, in which case I’d be more likely to drag my feet. Cynical or not, it was a totally legitimate view, and another perfect example of what I’m talking about. Effectively my friend wanted to replace a <em>manual</em> process—me consciously taking the time to help out a friend—with an <em>automatic</em> one—me responding to an internal, and basically involuntary, sense of obligation.</p>

<p>This kind of self-programming is hugely powerful, and is something I think we need to spend more time thinking about.</p>

<h2 id="how_we_get_it_wrong_2">How we get it wrong</h2>

<p>An interesting obstacle to self-automation that I’ve noticed among people I’ve worked with is the tendency to <strong>value manual effort</strong>. We appreciate when others take the time to stop what they’re doing and help us with something. And so there’s a sense of pride that comes with being asked to help out somewhere. We all love to feel needed, after all.</p>

<p>This makes it very easy to miss cases when the effort we spend is actually wasteful.</p>

<p>Imagine that my espresso machine were incredibly heavy, so heavy that I couldn’t even lift it. And suppose I had some much stronger friend who was capable of lifting it. Then whenever my friend was around and I was in the mood for some espresso, I would ask him to pick up the machine and put it on the table for me, so I could plug it in and use it. This arrangement might feel good to my friend as it would make him feel useful.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn:1">
<p>That actually isn’t the full story. The real reason I <em>still</em> haven’t used it is that there’s a part that we apparently lost somewhere between Philadelphia and here. But I’ve only included this detail in a footnote because it doesn’t really change my argument; I only even <em>noticed</em> this part was missing after we’d already been in our new apartment for several months. So it’s clear that I am not using the machine nearly as often as I used to. In addition, I’m hoping that by writing this post I will motivate myself to finally order a replacement for that part! <a href="#fnref:1" rev="footnote">↩</a></p>
</li>
<li id="fn:2">
<p>And don’t bother pointing me to an actual dictionary definition; I tend to be fairly dismissive of such things. But that’s a topic for a future post! <a href="#fnref:2" rev="footnote">↩</a></p>
</li>
</ol>
</div>]]></description><pubDate>Sun, 24 Feb 2013 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/automating-yourself.html</guid></item><item><title>Your brain is a liability</title><link>http://www.philosopherdeveloper.com/posts/your-brain-is-a-liability.html</link><description><![CDATA[<p>It’s natural to think of <em>being smart</em> as an asset. This is obvious in many ways, so I don’t feel I need to enumerate them. But there are also ways that it can be a liability; and since this is the contrarian view, I naturally want to talk about it<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>.</p>

<p>Before I start, though, a note about the word “smart”: it can mean many things. What I am specifically referring to now is what I will call raw <strong>brain power</strong>: the capacity of a person’s mind to think quickly, grasp tricky concepts, store a lot of information at once, and so on. If the mind were a computer, in other words, I’d be talking about <em>hardware</em> (CPU, memory, etc.) as opposed to software.</p>

<p>The <em>software</em> of a computer system makes <em>use</em> of the hardware. It isn’t the other way around. Powerful hardware on its own is useless. For the purpose of this argument I propose that we think of being “smart”–i.e., of having a lot of brain power—as analogous to having a computer with powerful hardware. In contrast, having good instincts, solid judgment, and a fresh perspective—characteristics more in line with what we generally call “wisdom”–is like running well-written software.</p>

<p>With this analogy in mind I think it makes some sense to conceptualize the brain as, quite simply, a <em>tool</em>. And framed in that way, I pose to you the question: if you were a carpenter<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>, and you had a top-of-the-line but rare and expensive tool—I don’t know; let’s say some custom-built <em>screwdriver</em>–would it be a wise idea to build cabinets that <em>required</em> your special tool to repair or disassemble? Or would it be better to build them with regular old screws that any ordinary screwdriver could tighten and loosen?</p>

<p>Maybe you don’t like that analogy. I’ll admit it isn’t perfect. Let’s get more concrete.</p>

<p>It takes being <strong>smart</strong> to be able to read through complex code and understand what it does. I’ve worked with really bright developers who can do this much more quickly and easily than I can. But this is dangerous. If it’s no trouble to <em>you</em> to understand something, you will be less likely to recognize that it is overly complicated and could be simplified—for the benefit of your teammates, and even for you, down the road. In contrast, if you struggle to understand what a section of code does, you will be much more inclined to work on making it <a href="/posts/optimize-for-comprehensibility.html">more comprehensible</a>.</p>

<p>Or suppose your code exhibits some strange behavior. There’s a subtle bug and no one on the team is quite sure what could be causing it. If you’re smart, your brain will scan its data banks of knowledge faster than any of your teammates; and while everyone else is scratching his head you may develop a <em>hunch</em> what the problem might be. But your hunch could be wrong, and you may end up wasting a lot of time exploring the wrong possibility. When you’re generally right about these things, it is all too easy to assume you’re <em>always</em> right. Your slower teammates will be more cautious about jumping to conclusions and may actually find the source of the problem through careful debugging while you’re busy following your intuition.</p>

<p>Being smart can also cause you to develop the tendency to go with your first idea for a design or an implementation, because your first idea is often a good one. But this doesn’t take into account how much your thinking is influenced by environmental factors, or how you might be “in the zone” at certain times and not at others. Meanwhile, your teammates have less confidence in their brains; so they force themselves to think through multiple alternatives before sitting down to write code. This could well lead them to come up with a superior solution to what you had in mind.</p>

<p>Now, I realize that in a sense all these examples may be construed as a form of <em>hubris</em>, or arrogance. So you could perhaps simplify my argument to this: <em>be careful if you’re really smart, because then you’re liable to become arrogant!</em> But the above are real examples (everything I’ve written about so far I’ve observed in real life); and they don’t actually require cocky or condescending personalities. These are traps that anyone who simply <em>is smart</em>–again, by which I mean, <em>has a really fast/powerful brain</em>–can fall into, regardless of attitude towards other people.</p>

<p>That said, your brain can certainly get in the way of your interactions with others as well.</p>

<p>A common saying is that the best way to learn is to teach. I find a lot of truth to this, especially when someone asks me to explain something and I realize I don’t have the firmest grasp of the subject myself. This leads to mutual learning, which is awesome. One problem I see smart people encounter at times is that they overestimate both their knowledge and their ability to explain things. If you’re smart and you find that someone doesn’t understand you, you’re more likely to attribute it to their smaller brain than to your failure to teach. This results in a double failure—you haven’t examined the holes in your own understanding, and your would-be student hasn’t learned anything.</p>

<p>It goes the other way, too. An even worse mistake that smart people make is to confuse others’ difficulty articulating their ideas with the ideas themselves being bad or misinformed. I’ve witnessed this a <em>lot</em>. The problem is that smart people’s brains work too fast; so while a slower-thinking person is stumbling through proposing a (potentially good) idea, a faster-thinking person evaluates it quickly and makes a premature judgment on the evidence available. This is one reason why I believe some smart people are prone to interrupting. Give your poor teammates a chance to sort out their thoughts while they’re talking! That’s how some people work out their ideas: by talking through them. Though you may grow impatient, it’s important to hear others out for this reason. Often I find that the real gem of a good idea comes right at the end of an otherwise inarticulate argument.</p>

<p>But the absolute <em>worst</em> mistake<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> smart people make, in my experience, is the “I already thought of that” fallacy. Smart people—by the very definition of “smart” that I laid out above—have brains that move quickly. This means that they tend to come up with more ideas at a faster rate than most of their peers. And if you have an idea, but you don’t pursue it, then presumably you have <em>reasons</em> for not pursuing it. So when a smart person’s colleague suggests an idea that the smart person already had, the smart person is very likely to dismiss it. <strong>It could still be a good idea.</strong> Just because you thought of something and then moved on does not mean it isn’t worth revisiting. It pains me to think of all the good ideas that have been dismissed, each simply because a smart person thought of it first but never bothered to actually try it.</p>

<p>My purpose in writing this is actually to address you smart folks directly: you know who you are. I’m not saying that you’re cocky, or arrogant, or anything like that. There are times<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> when <em>I’m</em> the one guilty of all the crimes I’ve outlined here. I’m also not denying that your brain is absolutely an asset in many ways—but you already know that. The respect of your team, your online reputation, the constant flood of recruiting messages in your LinkedIn inbox: these things already attest to that. What I am suggesting is that you consider your brain as a <em>tool</em>, with some drawbacks that you should be aware of.</p>

<p>Naturally, all else being equal, I would like a good brain, just as I’d like good PC hardware. But really powerful hardware can mask some of the problems with crappy software. And crappy software needs to be fixed.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn:1">
<p>I should say this right off the bat: these ideas are (clearly) not my own. I would attribute the seed of an idea underlying this article to Bill Schofield, another former ThoughtWorks teammate. Bill was patient enough to work with me on a project during which I believe I was myself guilty of most of the issues I write about here. <a href="#fnref:1" rev="footnote">↩</a></p>
</li>
<li id="fn:2">
<p>I swear one of these days I’ll think of another profession to constantly compare software development to other than carpentry. <a href="#fnref:2" rev="footnote">↩</a></p>
</li>
<li id="fn:3">
<p>I don’t know why I’d make such an extreme claim like this; I guess I’m just in the mood for some hyperbole. <a href="#fnref:3" rev="footnote">↩</a></p>
</li>
<li id="fn:4">
<p>This is generally not true at work, where I am quite possibly the dumbest person in the room. <a href="#fnref:4" rev="footnote">↩</a></p>
</li>
</ol>
</div>]]></description><pubDate>Fri, 08 Feb 2013 22:11:00 -0800</pubDate><guid>http://www.philosopherdeveloper.com/posts/your-brain-is-a-liability.html</guid></item><item><title>Unbreaking DataMapper</title><link>http://www.philosopherdeveloper.com/posts/unbreaking-datamapper.html</link><description><![CDATA[<h2 id="is_datamapper_inherently_broken_1">Is DataMapper inherently broken?</h2>

<p>In a <a href="http://www.drmaciver.com/2010/04/datamapper-is-inherently-broken/">strongly-worded blog post back in 2010</a>, David MacIver asserted that there is a fundamental flaw in <a href="http://datamapper.org/">DataMapper</a>, an ORM library for Ruby. The core of his complaint is<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> that DataMapper’s default API for saving records hides errors, making it difficult to diagnose what went wrong when something fails. This in turn increases the likelihood of defects going unnoticed during development and testing, resulting in buggier software.</p>

<p>Borrowing from MacIver’s post<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>, the below is a boilerplate example of how one might attempt to save a record and report any failures using DataMapper:</p>

<div class="highlight"><pre><span class="n">my_account</span> <span class="o">=</span> <span class="no">Account</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">"Jose"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">my_account</span><span class="o">.</span><span class="n">save</span>
  <span class="c1"># my_account is valid and has been saved</span>
<span class="k">else</span>
  <span class="n">my_account</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">e</span><span class="o">|</span>
    <span class="nb">puts</span> <span class="n">e</span>
  <span class="k">end</span>
<span class="k">end</span>
</pre></div>

<p>The above can be pretty annoying to anyone who expects conciseness from an API. Most developers don’t like the idea of having to write several lines of code just to save a record to a database.</p>

<p>Why not wrap the above into a common helper? This still won’t consistently work, as MacIvers points out with the following example:</p>

<div class="highlight"><pre><span class="n">my_account</span> <span class="o">=</span> <span class="no">Account</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">:customer</span> <span class="o">=&gt;</span> <span class="no">Customer</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="ss">:name</span> <span class="o">=&gt;</span> <span class="s2">"jose"</span><span class="p">))</span>
<span class="n">my_account</span><span class="o">.</span><span class="n">save</span>
</pre></div>

<p>In this case, an error could occur when saving <em>either</em> the <code>Account</code> object <em>or</em> the <code>Customer</code> object. And so a general-purpose helper wouldn’t be enough; one would have to write a special helper for every model, accounting for each of that model’s associations, in every application.</p>

<p>I certainly sympathize with MacIver’s frustration.</p>

<h2 id="why_use_datamapper_at_all_then_2">Why use DataMapper at all, then?</h2>

<p>It’s really a shame that such a “fundamental flaw”<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> exists in DataMapper. Otherwise, I find it to be quite a nice ORM, with at least a couple of (admittedly subjective) advantages over the more popular <a href="https://github.com/rails/rails/tree/master/activerecord">ActiveRecord</a>:</p>

<ol>
<li>With DataMapper, your database schema is defined in your models themselves. The ActiveRecord approach uses a separate file to define table schemas (schema.rb), making it sometimes awkward to reason about code in the classes used to interact with those tables. (The existence of gems such as <a href="https://github.com/ctran/annotate_models">annotate</a> attests to this awkwardness.)</li>

<li>DataMapper adopts the philosophy of having a 1:1 mapping between database records and objects in memory. Whereas in ActiveRecord you might have multiple <code>Account</code> instances referencing the same record (with different dirty local states), in DataMapper this is not the case. The upshot is the elimination of an entire category of bugs (<em>what happened to my attributes?</em>).</li>
</ol><h2 id="addressing_the_problem_3">Addressing the problem</h2>

<p>While I understand where MacIver was coming from when he wrote that original post, when I first read it I found myself scratching my head and wondering, <em>Why didn’t he do something about it?</em> This is particularly vexing given that MacIver mentioned having worked with DataMapper for at least “several months” and bemoaned encountering the same flaw “time and time again.” As a software developer, whenever I find myself repeatedly struggling with a tool–<em>especially</em> <a href="https://github.com/datamapper">an open source one</a>–I inevitably end up trying to patch it or otherwise find some way around its (perceived) shortcomings.</p>

<p>It should be noted that, probably at some point after MacIver’s post, DataMapper <em>did</em> introduce <a href="http://datamapper.org/docs/create_and_destroy.html">a <code>raise_on_save_failure</code> option</a> which (obviously) raises exceptions on save failures. However, these exceptions still don’t include any useful information; and it seems <a href="http://datamapper.lighthouseapp.com/projects/20609/tickets/1322-show-objecterrors-when-raise_on_save_failure-is-set">the DataMapper developers aren’t receptive to the idea that they should</a><sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>.</p>

<p>Luckily, it turns out that a solution to this problem isn’t even particularly complicated. It’s true that wrapping the above snippet into a helper in a <em>client application</em> doesn’t solve the problem; but wrapping it in <em>DataMapper</em> does.</p>

<div class="highlight"><pre><span class="k">module</span> <span class="nn">DataMapper</span>
  <span class="k">module</span> <span class="nn">Resource</span>
    <span class="n">alias_method</span> <span class="ss">:save?</span><span class="p">,</span> <span class="ss">:save</span>

    <span class="k">def</span> <span class="nf">save</span>
      <span class="k">return</span> <span class="k">if</span> <span class="nb">self</span><span class="o">.</span><span class="n">save?</span> <span class="o">||</span> <span class="nb">self</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">empty?</span>
      <span class="n">error_message</span> <span class="o">=</span> <span class="nb">self</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">map</span> <span class="p">{</span> <span class="o">|</span><span class="n">e</span><span class="o">|</span> <span class="s2">"</span><span class="si">#{</span><span class="nb">self</span><span class="o">.</span><span class="n">class</span><span class="si">}</span><span class="s2">: </span><span class="si">#{</span><span class="n">e</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">', '</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span> <span class="p">}</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">"; "</span><span class="p">)</span>
      <span class="k">raise</span> <span class="no">SaveFailureError</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="n">error_message</span><span class="p">,</span> <span class="nb">self</span><span class="p">)</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</pre></div>

<p>How is the above any different from writing a wrapper in your application? Simple: every time a resource is saved in DataMapper, the <code>save</code> method is called (internally). This means that in the simple case—where saving a record fails because it is invalid—the exception raised will be informative by reporting the record’s validation errors. In the more complex case—where saving a record fails because its child is invalid—the exception raised will be informative by reporting the <em>child’s</em> validation errors.</p>

<h2 id="enter_dmnoisyfailures_4">Enter dm-noisy-failures</h2>

<p>I’m sure you saw this one coming from a mile away. Yes, I wrote a gem to do what I’m describing: <a href="http://dtao.github.com/dm-noisy-failures">dm-noisy-failures</a> (the excerpt above is taken directly from the library). This gem overwrites DataMapper’s <code>save</code>, <code>update</code>, <code>create</code>, and <code>destroy</code> methods with variations that throw exceptions (with descriptive error messages) on failure. The original methods returning true and false are aliased as <code>save?</code>, <code>update?</code>, <code>create?</code>, and <code>destroy?</code>–a nice resolution, in my opinion, as it conforms to existing Ruby idioms.</p>

<p><a href="https://github.com/dtao/dm-noisy-failures">Check it out</a> and let me know what you think. <small>My quest to <a href="/posts/making-yaml-safe-again.html">actually publicize my open source projects</a> continues!</small></p>

<p>As <a href="http://www.drmaciver.com/blog">he still seems to be active</a>, and he also seems like a smart and thoughtful guy, I plan on contacting MacIver about my little gem to see what he thinks. It’s very possible he’s not even doing anything with DataMapper anymore; but it can’t hurt to seek his feedback. While I’m at it I should probably also get in touch with the DataMapper folks, who <a href="http://solnic.eu/2012/12/20/datamapper-2-status-and-roadmap.html">are currently working on a major update</a>.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn:1">
<p>To be fair, as the article was written in 2010, MacIver may have changed his stance between then and now. However, I did a brief search for any sort of retraction and couldn’t find one; so I’m sticking with the present tense here. <a href="#fnref:1" rev="footnote">↩</a></p>
</li>
<li id="fn:2">
<p>Which in turn borrows from the <a href="http://datamapper.org/docs/validations">official DataMapper documentation</a>. <a href="#fnref:2" rev="footnote">↩</a></p>
</li>
<li id="fn:3">
<p>I happen to agree with most of MacIver’s points, so I do view DataMapper’s API as flawed. But I’m also quite sure the library’s developers had reasons for designing it that way—or anyway, I haven’t seen any evidence to the contrary—so it’s clearly debatable to some extent. Hence my use of quotes. <a href="#fnref:3" rev="footnote">↩</a></p>
</li>
<li id="fn:4">
<p>As far as I can tell, the DataMapper team’s reasoning for excluding validation errors from exceptions is that “[the] #save command can return false for reasons other than validations being invalid.” This seems to me like an unfortunate case of <a href="http://en.wikipedia.org/wiki/Perfect_is_the_enemy_of_good"><em>the perfect is the enemy of the good</em></a>. <a href="#fnref:4" rev="footnote">↩</a></p>
</li>
</ol>
</div>]]></description><pubDate>Tue, 29 Jan 2013 23:21:00 -0800</pubDate><guid>http://www.philosopherdeveloper.com/posts/unbreaking-datamapper.html</guid></item><item><title>Making YAML safe again</title><link>http://www.philosopherdeveloper.com/posts/making-yaml-safe-again.html</link><description><![CDATA[<p>TL;DR: Check out my new gem, <a href="http://dtao.github.com/safe_yaml">SafeYAML</a>. It lets you parse YAML without exposing your app to security exploits via arbitrary object deserialization.</p>
<hr><p>There was <a href="http://news.ycombinator.com/item?id=5028218">quite a stir in the Rails community recently</a> about a serious security vulnerability in Rails. To be more specific: <a href="https://groups.google.com/forum/#!topic/rubyonrails-security/61bkgvnSGTQ/discussion"><em>every version of Rails</em></a>. We found out about this right away at <a href="http://www.cardpool.com/">Cardpool</a>, in part because Cardpool is a YC company and Paul Graham forwarded an e-mail from Thomas Ptacek to all YC alums warning of the vulnerability pretty much as soon as it was discovered.</p>

<p>Without getting too caught up in the weeds, I will just say the vulnerability was ultimately a consequence of the fact that Ruby’s <a href="http://www.yaml.org/">YAML</a> library by default permits the deserialization of arbitrary Ruby objects. This is a problem for Rails—as well as many other Ruby frameworks, to be fair—because, until patches were released to address this problem, any Rails app could be “tricked” into parsing malicious YAML by basically anybody, without any special credentials. The key weakness in Rails, specifically, was that Rails would automatically parse the parameters of any XML request, including parameters like this:</p>

<div class="highlight"><pre><span class="nt">&lt;data</span> <span class="na">type=</span><span class="s">"yaml"</span><span class="nt">&gt;</span>--- !ruby/object {}<span class="nt">&lt;/data&gt;</span>
</pre></div>

<p>I’m not giving anything away here; exploits <a href="https://community.rapid7.com/community/metasploit/blog/2013/01/09/serialization-mischief-in-ruby-land-cve-2013-0156">have already been made public</a>. The important takeaway is pretty simple: never parse YAML from untrusted user input. Not in an application, and <em>definitely</em> not in a framework. Which means, in the case of Rails, don’t automatically parse params as YAML. The patches that were released (and which we quickly deployed, obviously) addressed this issue by disabling XML parameter parsing by default. (Less aggressive patches were also made available for sites that needed to parse XML params by simply removing YAML from the list of types that could be embedded in an XML request.)</p>

<p>While this is probably fine for 9 out of 10 websites, and probably more than that since so few sites actually have any sort of API that accepts YAML—including Cardpool, I should add—it still felt a little frustrating to me, for a couple of reasons.</p>

<ol>
<li>YAML is, to me at least, a really sweet data format<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>.</li>

<li>This whole vulnerability nonsense <strong>could have been avoided in the first place</strong> if we were willing to give up one teensy weensy little feature of Ruby’s YAML library: the ability to deserialize arbitrary objects.</li>
</ol><p>Don’t get me wrong; I realize this can be a very useful feature, especially for tools that aim to hide away the details of sharing objects between processes (or entirely different machines). But in the context of a web service or an API, where you have an application and you want to send some information to my service, there’s no reason for you to even know what types <em>exist</em> within my application’s domain, let alone serialize or deserialize them. Strings, numbers, lists and maps are all we really need.</p>

<p>And so with this in mind—and after discovering that <a href="http://pyyaml.org/wiki/PyYAMLDocumentation#Loader">Python’s YAML module has a <code>safe_load</code> method</a>–I <a href="http://stackoverflow.com/questions/14348538/is-there-an-equivalent-to-yaml-safe-load-in-ruby">asked on StackOverflow</a> if there’s any way in Ruby to parse YAML without deserializing arbitrary objects. The answer I got led me to write a library that does precisely that: <a href="http://dtao.github.com/safe_yaml">SafeYAML</a><sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>.</p>

<p>Basically what SafeYAML does is override Ruby’s built-in <code>YAML.load</code> method with an implementation that only deserializes a safe set of types: strings, numbers, arrays, hashes, and a few others. The beauty (in my humble opinion) of this approach is that it makes SafeYAML a great drop-in enhancement to any website that directly or indirectly parses user-supplied YAML. Simply by adding a dependency on the <a href="http://rubygems.org/gems/safe_yaml">gem</a>, without any additional code changes, you can have your cake and eat it too: re-enable YAML parsing in your application, without exposing yourself to a well-known exploit.</p>

<p>Check it out and let me know what you think! Bug reports, pull requests, etc. all welcome <a href="https://github.com/dtao/safe_yaml">on GitHub</a>.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn:1">
<p>Even while I typed that sentence, I felt <em>sure</em> there are articles I could find pretty quickly on Google about why YAML sucks. I choose not to seek out these articles (yet). <a href="#fnref:1" rev="footnote">↩</a></p>
</li>
<li id="fn:2">
<p>As a side note, one of my goals for 2013 (a little late to call it a resolution I suppose) is to actually maintain and publicize the growing number of mostly-open-source projects I’ve started and, in most cases, abandoned over the years. Some are pretty far along; others are still little seedlings; still others exist nowhere but in my brain. But I think a worthwhile aim for this year is to go back through all of these projects and either get back to work on them or scrap them for good. SafeYAML is just the first of many. <a href="#fnref:2" rev="footnote">↩</a></p>
</li>
</ol>
</div>]]></description><pubDate>Thu, 24 Jan 2013 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/making-yaml-safe-again.html</guid></item><item><title>A/B testing and irreducible complexity</title><link>http://www.philosopherdeveloper.com/posts/ab-testing-and-irreducible-complexity.html</link><description><![CDATA[<p>I was raised in a devout Christian family, which resulted in a fair amount of inner conflict and soul-searching throughout my academic life, <em>particularly</em> with respect to my ninth-grade education on evolution<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>. This in turn ultimately led me to read a book called <a href="http://www.amazon.com/Darwins-Black-Box-Biochemical-Challenge/dp/0743290313">Darwin’s Black Box</a> by Michael Behe, which argues in favor of <a href="http://en.wikipedia.org/wiki/Intelligent_design">intelligent design</a><sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> on the basis of a concept called <a href="http://en.wikipedia.org/wiki/Irreducible_complexity"><strong>irreducible complexity</strong></a>. It is actually a pretty reasonable argument, in my opinion—though I’m admittedly no expert on the subject—at least in that its premise seems plausible. To summarize in one sentence: Behe argues that there are systems in present-day organisms consisting of interacting parts, each of which on its own would provide no reproductive advantage to an individual and so cannot be explained purely by Darwinian natural selection. Only taken <em>as a whole</em> do these systems provide reproductive advantages; and so some other process must have generated them (where intelligent design enters the picture).</p>

<p>Behe provides plenty of low-level biochemical examples that I won’t bother you with, primarily because I don’t remember them. But whether or not you agree with his argument—and my limited research leads me to believe that (surprise!) most of the scientific community does <strong>not</strong>–I think the <em>concept</em> of irreducible complexity is a useful one. Even if Behe is wrong with respect to evolution, we all know and probably to some extent accept the idea behind <em>the whole is greater than the sum of its parts</em>. Not everything in this world is the end result of some sequence of perfectly incremental changes, each coherent and explicable in its own right. Morever, if a whole could be greater than the sum of its parts, this leaves open the possibility that any given part on its own could even have <em>negative</em> effects, and only contribute towards a positive whole in concert with other parts.</p>

<p>This is a particularly important lesson for software developers—we who are practically hard-wired to test the validity of every assumption and break all problems into smaller pieces. We do love our A/B testing; but as <a href="http://techcrunch.com/2013/01/12/current-conversion-rate-and-desired-confidence-interval-will-help-you-avoid-analysis-paralysis-stop-running-stupid-tests/">Robert J. Moore recently wrote in an article on TechCrunch</a>, these can be taken too far. I have been disheartened on more than one occasion by data-driven minds pushing to validate a large feature through A/B testing each of its smaller parts individually, only to “discover” that the feature had no impact, or even a negative impact, on whatever was being measured. I can’t prove it (without buy-in, that is), but my suspicion is often that the larger feature <em>in its complete form</em> might still have yielded positive results in these cases.</p>

<p>It’s difficult to make this argument, though. The obsessively data-driven approach is actually a very scientific way of tackling a problem: as we all learned in science class, the only true way to test a variable is in isolation, with all other potential factors held constant. One of the problems with applying this scientific methodology to a software project, of course, is that you cannot possibly hold all factors but one constant. The market, your competitors, your users—everything is changing around you at all times. But even if you <em>could</em> somehow contain all that, there remains that nagging possibility that Behe was right, and you risk breaking a big good thing into many small bad things.</p>

<p>How do you draw the line? I’m afraid I don’t have a satisfying answer to that. But from experience, I think I prefer to lean closer to the “test the whole feature” side of the spectrum than the “test each part by itself” side.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn:1">
<p>Not that my parents were Biblical literalists. I never heard either my mom or my dad argue with any passion for a <a href="http://en.wikipedia.org/wiki/Young_earth">Young Earth</a>, for example. I’m inclined to believe my sense of friction between religion and science during my formative years was as much a result of anti-religious sentiments among my science teachers (and peers) as anything else. <a href="#fnref:1" rev="footnote">↩</a></p>
</li>
<li id="fn:2">
<p>Not necessarily of theistic origin. <a href="#fnref:2" rev="footnote">↩</a></p>
</li>
</ol>
</div>]]></description><pubDate>Sun, 13 Jan 2013 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/ab-testing-and-irreducible-complexity.html</guid></item><item><title>Optimize for comprehensibility</title><link>http://www.philosopherdeveloper.com/posts/optimize-for-comprehensibility.html</link><description><![CDATA[<h1 id="starting_with_an_outline_1">Starting with an outline</h1>

<p>More than one of my high school English teachers taught us that when you’re writing a paper, you should start by making an outline of your high-level points. This way, they told us, you would have a “skeleton” paper already written, which you could then “flesh out” by filling in appropriate details here and there.</p>

<p>I never much internalized this process of starting off with an outline. I wish I had.</p>

<h1 id="to_design_or_assemble_2">To design or assemble</h1>

<p>My first project at <a href="http://www.thoughtworks.com/">ThoughtWorks</a> was in Dallas, TX. During a car ride back to the office after lunch one day, I was having a conversation with Billy, one of the client company’s developers; and he mentioned that he had recently been to a Google conference to learn about <a href="https://developers.google.com/web-toolkit/">Google Web Toolkit</a> (one of the technologies we were using on the project), among other things. I can’t recall everything we talked about, but something that Billy said during that conversation has stuck with me ever since:</p>

<blockquote>
<p>Companies like Google, Microsoft, Apple—they are the LEGO makers. We are just the assemblers.</p>
</blockquote>

<p>At the time, I strongly disagreed with Billy on this point. Part of me wanted to blurt out, “Speak for yourself!” I didn’t say that, of course; in fact I wasn’t even sure why I felt so strongly in opposition to this statement. Probably more than any other reason, I was just feeling defensive against what I felt was a belittling thing to say about being a software developer.</p>

<p>What I <em>did</em> say was something to the effect that we are all LEGO makers in the sense that we should strive to write clean code, to design clear interfaces, to build reusable components, etc. Billy smiled but clearly didn’t agree with me. In retrospect, he probably thought I was being naïve.</p>

<h1 id="a_lesson_on_refactoring_3">A lesson on refactoring</h1>

<p>On that same project, I became friends with a fellow ThoughtWorks developer, <a href="http://seleniumcapsules.blogspot.com">Yujun Liang</a>. I really enjoyed <a href="http://en.wikipedia.org/wiki/Pair_programming">pairing</a> with Yujun; he and I both understood each other fairly quickly<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, and we got along quite well.</p>

<p>One habit of Yujun’s that bugged me, though, was that he <em>loved</em> to refactor code. In contrast, I had a tendency (at the time) to prefer moving more quickly and building more features. I did understand the value of refactoring in many cases, such as to reduce code duplication. However, Yujun consistently engaged in a particular type of refactoring that I, at the time, found somewhat maddening.</p>

<p>Since a code snippet will probably better illustrate this type of refactoring than I could with words, here’s an example. Suppose we came across this (completely fabricated) code on our project:</p>

<div class="highlight"><pre><span class="kd">public</span> <span class="kt">void</span> <span class="nf">sendNotifications</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">Notification</span><span class="o">&gt;</span> <span class="n">pendingNotifications</span> <span class="o">=</span> <span class="n">getPendingNotifications</span><span class="o">();</span>

    <span class="c1">// Group notifications by recipient.</span>
    <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Notification</span><span class="o">&gt;&gt;</span> <span class="n">notificationsByRecipient</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Notification</span><span class="o">&gt;&gt;();</span>
    <span class="k">for</span> <span class="o">(</span><span class="n">Notification</span> <span class="n">n</span> <span class="o">:</span> <span class="n">pendingNotifications</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">String</span> <span class="n">recipient</span> <span class="o">=</span> <span class="n">n</span><span class="o">.</span><span class="na">getRecipient</span><span class="o">();</span>
        <span class="k">if</span> <span class="o">(!</span><span class="n">notificationsByRecipient</span><span class="o">.</span><span class="na">containsKey</span><span class="o">(</span><span class="n">recipient</span><span class="o">))</span> <span class="o">{</span>
            <span class="n">notificationsByRecipient</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="n">recipient</span><span class="o">,</span> <span class="k">new</span> <span class="n">ArrayList</span><span class="o">&lt;</span><span class="n">Notification</span><span class="o">&gt;());</span>
        <span class="o">}</span>
        <span class="n">notificationsByRecipient</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">recipient</span><span class="o">).</span><span class="na">add</span><span class="o">(</span><span class="n">n</span><span class="o">);</span>
    <span class="o">}</span>

    <span class="c1">// For each recipient, create a new notification task to be executed by the scheduler.</span>
    <span class="n">Set</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">recipients</span> <span class="o">=</span> <span class="n">notificationsByRecipient</span><span class="o">.</span><span class="na">keySet</span><span class="o">();</span>
    <span class="k">for</span> <span class="o">(</span><span class="n">String</span> <span class="n">recipient</span> <span class="o">:</span> <span class="n">recipients</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">List</span><span class="o">&lt;</span><span class="n">Notification</span><span class="o">&gt;</span> <span class="n">notificationsForRecipient</span> <span class="o">=</span> <span class="n">notificationsByRecipient</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">recipient</span><span class="o">);</span>
        <span class="n">NotificationTask</span> <span class="n">task</span> <span class="o">=</span> <span class="k">new</span> <span class="n">NotificationTask</span><span class="o">(</span><span class="n">recipient</span><span class="o">);</span>
        <span class="k">for</span> <span class="o">(</span><span class="n">Notification</span> <span class="n">n</span> <span class="o">:</span> <span class="n">notificationsForRecipient</span><span class="o">)</span> <span class="o">{</span>
          <span class="n">task</span><span class="o">.</span><span class="na">addNotification</span><span class="o">(</span><span class="n">n</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="n">task</span><span class="o">.</span><span class="na">scheduleForDelivery</span><span class="o">();</span>
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>

<p>Yujun would refactor the above into something like this:</p>

<div class="highlight"><pre><span class="kd">public</span> <span class="kt">void</span> <span class="nf">sendNotifications</span><span class="o">()</span> <span class="o">{</span>
    <span class="n">Map</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">List</span><span class="o">&lt;</span><span class="n">Notification</span><span class="o">&gt;&gt;</span> <span class="n">notificationGroups</span> <span class="o">=</span> <span class="n">groupNotificationsByRecipient</span><span class="o">(</span><span class="n">getPendingNotifications</span><span class="o">());</span>
    <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">NotificationTask</span><span class="o">&gt;</span> <span class="n">tasks</span> <span class="o">=</span> <span class="n">createNotificationTasksFromGroups</span><span class="o">(</span><span class="n">notificationGroups</span><span class="o">);</span>
    <span class="n">scheduleNotificationTasksForDelivery</span><span class="o">(</span><span class="n">tasks</span><span class="o">);</span>
<span class="o">}</span>

<span class="c1">// same implementation as above, just broken up into methods</span>
</pre></div>

<p>Here’s what bothered me about this kind of refactoring at the time: <em>there was still functionality to build.</em> While I would have conceded that Yujun’s refactoring arguably made the code more <em>readable</em>, it did not get us any closer to completing the <a href="http://en.wikipedia.org/wiki/User_stories">stories</a> we needed to finish that iteration. For me, that meant it was not an appropriate use of our time as (expensive) consultants. It was not even reducing code duplication, as the code in question only appeared in one place. I felt this sort of thing belonged at the bottom of a prioritized list of work.</p>

<h1 id="the_limited_value_of_locality_4">The limited value of locality</h1>

<p>You have probably picked up from my careful use of past-tense verbs that my stance on this has changed in the time since that project with Yujun. It has—but not in such a simplistic way that I’d say, “I was wrong, he was right, end of story.” I now think there’s a more nuanced way of looking at how code should read and the value of this style of refactoring. To explain what I mean, let me fast forward to my more recent experience at <a href="http://www.cardpool.com/">Cardpool</a>.</p>

<p>When I first joined the company, every commit I made was code reviewed by a fellow engineer. Very early on—probably within my first couple of weeks—my teammate commented to me that he noticed I tend to write lots of short methods whereas the rest of the engineers on the team generally wrote longer methods. It wasn’t a criticism, just an observation. We agreed that we all have different styles and that there’s an argument that can be made either way: a higher number of shorter methods can lead to more reusable code that’s easier to unit test; whereas favoring fewer, longer methods offers the advantage of greater <strong>locality</strong>: you can see everything the code is doing in one place, without having to navigate back and forth between multiple places in a file (or between multiple files).</p>

<p>I would still say this is true to some extent. But curiously, the longer I’ve been at Cardpool, working in a codebase where this <em>fewer-longer-methods</em> style is the prevailing one, the more I’ve started to doubt one of the supposedly greatest benefits of locality: that it makes code easier to understand. I’ve found that long methods can have the opposite effect: when you have to scroll multiple times the height of your screen to read the entirety of a method’s code, locality falls apart. There’s so much to hold in your brain at once, it becomes difficult to reason about what the code is doing, where changes should be made, and what impact they’ll have.</p>

<p>I think there’s certainly some point at which you can go too far in the opposite direction; i.e., to make the <em>reductio ad absurdum</em> argument, suppose you committed to never writing methods longer than a single line. Reading such code would be like trekking through a treacherous jungle, a veritable nightmare. So, as with most things in life, there’s a balance to be reached. I just happen to believe that the optimal balance is pretty far down towards the “shorter” end of the spectrum.</p>

<h1 id="details_are_irrelevant_yet_responsible_5">Details are irrelevant yet responsible</h1>

<p>I just started reading the book <em>I am a Strange Loop</em> by Douglas Hofstadter (easily one of my favorite authors after reading <a href="http://en.wikipedia.org/wiki/Godel_escher_bach"><em>Gödel, Escher, Bach</em></a>); and in one of the earlier chapters he discusses the notion that <strong>the low-level details of a system are simultaneously <em>responsible</em> for the system functioning yet <em>irrelevant</em> to how the system works</strong>. I think it was while reading this passage that the idea I’m working towards truly started to crystallize for me:</p>

<blockquote>
<p>[L]et us think for a moment about […] a gas in a cylinder with a movable piston. If the gas suddenly heats up (as occurs in any cylinder in your car engine when its spark plug fires), then its pressure suddenly increases and <em>therefore</em> (note the causal word) the piston is suddenly shoved outwards. Thus combustion engines can be built.</p>

<p>What I just told is the story at a gross (thermodynamic) level. Nobody who designs combustion engines worries about the fine-grained level—that of molecules. No engineer tries to figure out the exact trajectories of 1023 molecules banging into each other! The locations and velocities of individual molecules are simply irrelevant. All that matters is that they can be counted on to <em>collectively</em> push the piston out. Indeed, it doesn’t matter whether they are molecules of type X or type Y or type Z—pressure is pressure, and that’s all that matters. The explosion—a high-level event—will do its job in heating the gas, and the gas will do its job in pushing the piston. This high-level description of what happens is the <em>only</em> level of description that is relevant, because all the microdetails could be changed and exactly the same thing (at least from the human engineer’s point of view) would still happen.</p>
</blockquote>

<p>I love this, and I think it covers a concept that is extremely useful for us software engineers. Embrace the notion that the low-level <em>implementation</em> (details) of software, while indisputably <em>responsible</em> for how that software works, can be at the same time irrelevant, extraneous, unimportant—however you want to put it—to understanding the software at a higher level.</p>

<p>Elsewhere in the book, Hofstadter makes this more general point about how much of our understanding of the world actually relies on, essentially, <em>ignoring</em> lower-level details:</p>

<blockquote>
<p>To describe a gas’s behavior by writing a gigantic piece of text having Avogadro’s number of equations in it (assuming such a herculean feat were possible) would not lead to anyone’s understanding of anything. But throwing away huge amounts of information and making a statistical summary could do a lot for comprehensibility. Just as I feel comfortable referring to “a pile of autumn leaves” without specifying the exact shape and orientation and color of each leaf, so I feel comfortable referring to a gas by specifying just its temperature, pressure, and volume, and nothing else.</p>
</blockquote>

<h1 id="the_importance_of_a_consistent_abstraction_6">The importance of a consistent abstraction</h1>

<p>Through experience, reading, and thinking a lot on my own I’ve come to appreciate Yujun’s style of refactoring much more over time. I think I understand better now how important such work is to the sustained health of a codebase. But even though I appreciate the <em>intent</em>, there remains the question of what the end result should be.</p>

<p>A mantra that many of us have heard is that “good code should read like prose”–a quote I want to attribute to <a href="http://en.wikipedia.org/wiki/Donald_Knuth">Donald Knuth</a>, but I could be wrong—and I’m inclined to <em>sort of</em> agree with that. It’s right in line with another mantra we’ve all heard: that when writing code, you should “optimize for readability” (as opposed to, e.g., performance). These are good guidelines, but in my opinion they only get us about halfway to where we should be.</p>

<p>I was fortunate enough to work with <a href="http://blog.thepete.net">Pete Hodgson</a>, another former ThoughtWorks teammate, on multiple projects. On our first project together, Pete took up the burden of teaching me a valuable lesson about how <em>not</em> to write code, in response—to my embarrassment—to a rather clumsy bit of work I had done.</p>

<p>Pete noticed that in one of my commits I had added a snippet of code in a place where, from an organizational standpoint, it simply didn’t belong. <em>Functionally</em> the code did what I intended; but its placement was haphazard, something I hadn’t put any reasonable amount of thought into. I would compare my process for picking its location to spinning a globe and landing your finger on a random spot and declaring: “That’s where I’ll build my house!”</p>

<p>The problem actually went beyond the poor placement of a code snippet within a larger codebase, though. I really can’t recall what the actual code was, so I’ll just write another little fabrication to illustrate the problem:</p>

<div class="highlight"><pre><span class="c1">// what was already there</span>
<span class="nx">updateListContents</span><span class="p">();</span>
<span class="nx">attachEventHandlers</span><span class="p">();</span>
<span class="nx">refreshStyles</span><span class="p">();</span>

<span class="c1">// what I added</span>
<span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">pages</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">pageIsHidden</span><span class="p">(</span><span class="nx">pages</span><span class="p">[</span><span class="nx">i</span><span class="p">]))</span> <span class="p">{</span>
    <span class="nx">hideDialogs</span><span class="p">(</span><span class="nx">pages</span><span class="p">[</span><span class="nx">i</span><span class="p">]);</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>

<p>Again, that isn’t the actual code I wrote; but I’m pretty confident it was something like that. In retrospect, I’m pretty ashamed to admit that I <em>ever</em> failed to see the problem there. But as Pete was kind enough to articulate for me, and as I quickly understood, there most certainly is a problem: the above code fails to maintain a <strong>consistent abstraction level</strong>.</p>

<p>It was as if Yujun had started to refactor the code, then got pulled away to work on something else. Or, to return to Hofstadter’s point about irrelevant details, it was as though I started to tell you a story by describing some events that occurred and the actions different characters performed, then got to a scene where two characters play a game of chess and suddenly started listing every single move. This has a jarring, botched effect—in code <em>or</em> in prose. Such inconsistency pulls you out from a level of understanding and plunges you “into the weeds”–as apt a metaphor as I’ve heard to describe this sort of thing—by providing <em>detail that is irrelevant to a high-level understanding of what’s important</em>.</p>

<h1 id="what_comprehensible_code_looks_like_7">What comprehensible code looks like</h1>

<p>I mentioned that I only half-agree with the assertion that code should read like good prose. Actually, it might have made sense to say that at the time, whoever first said it. But I would argue that with the advent of <a href="http://en.wikipedia.org/wiki/Hypertext">hypertext</a> we’ve gained an even better way to present information than prose, which is generally linear. The more I think on this idea, the more I like it: <strong>unlike prose, good code should read like Wikipedia</strong>.</p>

<p>Some of you probably instinctively know what I mean by this, but let me explain. When you read an article on Wikipedia (in hypertext), you get a high-level description of some subject—a historical event or figure, a technology, a scientific theory, etc. This description maintains what I’ll call a consistent “altitude”–that is, let’s say, a 10,000-foot view. A well-written article keeps this altitude without diving much deeper; that is left to the reader who wants to find out more about some subtopic of the current subject.</p>

<p>When you <em>do</em> find some part of an article on Wikipedia fascinating, what normally happens (at least with me) is you find yourself clicking on links which take you to more details or otherwise provide greater context on whatever you happen to be reading about. This is a great way to provide information, as it is easy to comprehend—thanks to a consistent altitude—while it also empowers the reader to explore ideas in a way that naturally follows his or her own curiosity. (Incidentally, this also makes Wikipedia a very dangerous place if you can’t afford to waste a lot of time!)</p>

<p>And of course, I could replace the word “altitude” in the above paragraphs with “abstraction level” and suddenly we’d be talking about code. Good code is written like a good Wikipedia article—at a consistently high level of abstraction, so that it can be easily understood, but also in a way that invites <em>exploration</em> to the curious developer who wants to know how this method is implemented, or what dependencies that class has, or how these interfaces fit together.</p>

<p>(As a sort of unfortunate aside, I feel compelled to point out—or admit?–that what I’m saying does require a certain level of sophistication among developers’ tools, just as hypertext requires web browsers offering more functionality than simple text viewers. I’m a huge fan of “lean” editors such as <a href="http://www.sublimetext.com/">Sublime Text</a>, or to a lesser extent <a href="http://www.gnu.org/software/emacs/">emacs</a> or <a href="http://www.vim.org/">vim</a>; but with respect to the point I’m making about code reading like hypertext, I do think it’s worth calling out the advantage of both statically typed languages and beefier IDEs such <a href="http://www.eclipse.org/">Eclipse</a> and <a href="http://www.microsoft.com/visualstudio">Visual Studio</a>.)</p>

<p>To provide one more example: if someone asks you what you do professionally, do you start by going through every task you perform on a daily basis at your job and explaining each one in detail? No, you start with a high-level answer, like ”I’m a software engineer” or ”I’m an investment banker” or ”I’m in sales.” If this person asks you follow-up questions, <em>then</em> you provide more information. The more interest someone shows in what you have to say, the more you can go into detail with the confidence he or she actually cares to hear it. In this sense writing code is similar to telling a story or having a conversation.</p>

<h1 id="optimizing_for_the_right_thing_8">Optimizing for the right thing</h1>

<p>This has really all been a long-winded way of saying: <em>absolutely</em> prefer shorter methods. I’m willing to put a stake in the ground on this one now. The more I write software, and the more I think about it, the more I become convinced that this is a crucial part of writing good code that others can understand. Start with the 10,000-foot view, maintain that altitude, and let the reader (i.e., your teammates) decide when to drill deeper for more detail. In this way your code will be <em>discoverable</em>, like a Wikipedia article, and not just <em>linear</em>, like standard prose.</p>

<p>I should be clear about something at this point. I don’t think that writing long methods makes you a bad engineer, or that writing short methods makes you a good one. I do think I’m right on this issue; but I also know there are other engineers (including some of my current teammates) who would likely disagree with me, yet from whom I still have plenty to learn. Probably more importantly, I can’t even claim to be particularly effective at practicing what I preach, at least at the moment. It’s an opinion that has only recently solidified for me, and one that will require a lot of self-discipline for me to start applying consistently to my work.</p>

<p>But there’s a reason I wrote all this, and it all comes back to what Billy said about being assemblers. I think this is at least partially wrong, because even if we are assemblers in some ways, we are also <em>designers</em>; and any system that is designed well must be comprehensible. That’s why I don’t think it’s enough to just write code that gets the job done, nor do I think that “readability” is the right word to describe how we make code accessible to others. Optimizing for <em>comprehensibility</em> is all about abstraction, or as Hofstadter put it: “throwing away huge amounts of information.” It’s about <em>hiding</em> detail, not revealing it all in one place.</p>
<div class="footnotes">
<hr>
<ol><li id="fn:1">
<p>As anyone who’s seriously worked in a pair programming environment before knows, the importance of clear communication between developers is absolutely critical to their ability to work effectively. I’ve sadly had the experience more than once of working with otherwise talented developers with whom I struggled to communicate; and our productivity inevitably suffered as a result. <a href="#fnref:1" rev="footnote">↩</a></p>
</li></ol>
</div>]]></description><pubDate>Sat, 29 Dec 2012 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/optimize-for-comprehensibility.html</guid></item><item><title>The universe is a one-way function</title><link>http://www.philosopherdeveloper.com/posts/universe-is-a-one-way-function.html</link><description><![CDATA[<p>Recently my friend Chuck reminded me of a conversation he and I had ages ago about a company called <a href="http://steorn.com/">Steorn</a>. This is a company that publicly claimed, back in 2007, to have developed an <a href="http://en.wikipedia.org/wiki/Overunity">overunity</a> technology. Chuck chastised me for having persuaded him to take the company seriously; to this day, despite their refusal to back down, they have still not convincingly <a href="http://en.wikipedia.org/wiki/Second_law_of_thermodynamics">broken the second law of thermodynamics</a>.</p>
<iframe width="480" height="360" src="http://www.youtube.com/embed/Xy0UBpagsu8" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
<p>Most of my acquaintances with a modest amount of scientific knowledge, of course, dismissed Steorn from the very start. What the company claims to do violates a known law of physics, they argued; therefore it is impossible; therefore they are either lying or confused. Personally, I never did and probably never will fully sympathize with this attitude. While I agree that Steorn probably do not have what they have claimed (and I certainly have no intention of arguing with the laws of thermodynamics!), I disagree with the premise that we can be <em>so sure</em> of things like this that we are justified in rejecting them immediately.</p>

<p>This is actually the same topic I covered in <a href="http://philosopherdeveloper.wordpress.com/2009/12/19/the-myth-of-the-myth-of-perpetual-motion/">my very first post on this blog</a>. But it’s something I feel quite strongly about, so I’ll probably write about it again, and again, until I’m satisfied I’ve fully covered the topic in the way I want (i.e., never). This time around, I want to relate my skepticism<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> in these sorts of matters to the concept of <em>one-way-functions</em>–a mathematical term that I’ll define later in this post. But first, I’ll start with a simple problem.</p>

<h2 id="recognizing_patterns_1">Recognizing patterns</h2>

<p>Back in the old K–12 days, I remember sometimes taking tests with <em>pattern recognition</em> questions. As a kid, I was always frustrated by these questions because I felt that they generally had no right answer. For example, consider this sequence:</p>

<pre><code>1, 2, 4, ...</code></pre>

<p>What is the next element in the above sequence?</p>

<p>If you say <em>8</em>, you’re most likely thinking that the “pattern” illustrated above involves every value in the sequence doubling the previous value:</p>

<pre><code>1, 2, 4, 8, 16, 32, ...</code></pre>

<p>But there are other possible patterns. For example, we could start with 1, and then add linearly increasing values (+1, +2, +3, etc.):</p>

<pre><code>1, 2, 4, 7, 11, 16, ...</code></pre>

<p>Or the pattern could simply consist of the values <em>1, 2, 4</em> repeated over and over:</p>

<pre><code>1, 2, 4, 1, 2, 4, ...</code></pre>

<p>These are all <em>patterns</em>; and they all start the same way, which means that there is no “right” answer to a question like this. There is, in fact, an infinite number of possible patterns I could imagine that would begin with <em>1, 2, 4</em>, and then proceed in an endless variety of ways. So there are infinitely many equally “right” answers to the question.</p>

<h2 id="the_problem_of_deduction_2">The problem of deduction</h2>

<p>The human ability to recognize patterns and predict outcomes based on those patterns is <em>deduction</em>.</p>

<p>There is a game of deduction that a few of my friends like to play called <em>Zendo</em>.</p>

<figure><img src="/images/zendo.jpeg" alt="Zendo"><figcaption>Zendo</figcaption></figure>

<p>In Zendo, one player—the Master—devises a rule involving the game pieces, which he then illustrates via two examples: one embodying the rule, and one not. These examples are designated <em>true</em> and <em>false</em>. The players then take turns assembling their own game pieces in different formations, asking the master whether or not their formations comply with the master’s rule. Eventually, one or more of the players will <em>deduce</em> the rule by observing a <em>pattern</em> across the examples.</p>

<p>I was recently surprised<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> when, during a game, after the master had given his initial two examples, one of my friends announced that he knew the rule already.</p>

<p>This declaration of having the answer so early in the game seemed absurd to me. And I think you can understand why, from my earlier thoughts on pattern recognition. There was no way my friend already <em>knew</em> the rule at this stage, given that there were many possible rules that would be consistent with the examples given.</p>

<p>Put another way: my friend had not narrowed down the possibilities enough to justify his feeling of certainty, at least to my thinking. He was guilty of <strong>overeager deduction</strong>.</p>

<figure><img src="/images/premature_deduction.jpg" alt="Overeager deduction"><figcaption>Overeager deduction</figcaption></figure>

<p>That said, I can’t really blame him. We humans do this all the time. We <em>have</em> to, because the alternative—i.e., basing our beliefs on logical certainties—is completely impractical. But I’ll get to that. Time to shift gears.</p>

<h2 id="oneway_functions_3">One-way functions</h2>

<p>In mathematics, a <a href="http://en.wikipedia.org/wiki/One-way_function">one-way function</a> is one where computing the <em>output</em> for a given <em>input</em> is easy; but performing the reverse is much harder.</p>

<p>This is in contrast to a <em>two-way</em> function, which is easy to reverse. An example of a two-way function would be multiplication. Given an equation like <em>y = 3x</em>, when we apply the <em>input</em> of 5, we simply multiply 3 × 5 and get the <em>output</em> 15. Likewise, if we know the <em>output</em> is 15, we divide 15 &amp;div; 3 and conclude that the <em>input</em> must have been 5.</p>

<p>An example of a <em>one-way</em> function is <a href="http://en.wikipedia.org/wiki/Prime_factorization">prime factorization</a>. Take some large non-prime number—say, 946,905,102,747. Can you tell me this number’s prime factors, i.e., what prime numbers divide it evenly?</p>

<p>This is not an easy problem to solve efficiently. The only obvious way is to just go through prime numbers, one by one, until you’ve found all the factors. Finding an answer in this way would obviously take a very long time for a human being.</p>

<p>However, it is very <em>easy</em> to <em>verify</em> when I tell you that these are the factors:</p>

<pre><code>27, 101, 419, 857, 967</code></pre>

<p>Even without a calculator, it would not take too long to multiply these numbers together and confirm that they indeed all multiply up to 946,905,102,747.</p>

<p>Here, the function in question might be worded in plain English as: <em>What do you get when you multiply all of these prime numbers together?</em> It is very easy to compute the <em>output</em> of this function given the above factors as <em>input</em>. The reverse might be worded: <em>What prime numbers would you have to multiply together to get this number?</em> From the <em>output</em>, figuring out the <em>input</em> is much harder.</p>

<h3 id="data_encryption_4">Data encryption</h3>

<p>With one-way functions, then, what we effectively have are problems that are difficult to <em>solve</em>, yet whose solutions are easy to <em>verify</em>. It turns out that these are highly useful properties in the context of software security. One-way functions constitute one of the fundamental building blocks of data encryption.</p>

<p>An illustration of this is the way passwords are stored. If you create an account with my website, and I then save your password <em>directly</em> in my database, then a hacker who breaks onto my servers can easily read your password.</p>

<figure><img src="/images/plaintext_password.png" alt="Plaintext password"><figcaption>Plaintext password</figcaption></figure>

<p>But suppose instead of storing your password itself, I store the output of some cryptographic (one-way) function, using your password (and perhaps a <a href="http://en.wikipedia.org/wiki/Password_salting">salt</a>) as input.</p>

<figure><img src="/images/encrypted_password.png" alt="Encrypted password"><figcaption>Encrypted password</figcaption></figure>

<p>Now, even if a hacker breaks into my system and sees your <em>encrypted</em> password, it will be very difficult for him or her to figure out what your password actually <em>is</em>–much in the same way it would be difficult for you to factor the number 946,905,102,747. However, it’s very easy for my system to <em>authenticate</em> you when you enter your <em>real</em> password, just as it is easy for you to multiply the factors of that number together once I tell them to you.</p>

<h3 id="oneway_functions_and_black_boxes_5">One-way functions and black boxes</h3>

<p>It might seem that I’ve veered off topic a bit. How are pattern recognition, Zendo, and one-way functions all related?</p>

<p>I believe the concept of a one-way function is broader than you might think from my initial examples.</p>

<p>In Zendo, we can think of a <em>rule</em> as its own kind of function. The input to this function is a formation of game pieces, and the ouput is either true or false.</p>

<figure><img src="/images/zendo_function.png" alt="Zendo as a one-way function"><figcaption>Zendo as a one-way function</figcaption></figure>

<p>Clearly, this function is itself one-way. Given either <em>true</em> or <em>false</em>–even if you already <em>knew</em> the rule—how could you possibly deduce which formation led to that result?</p>

<p>Of course, that isn’t quite the challenge of the game. In Zendo, the players don’t even know what the function <em>is</em>. This is why in the diagram above I’ve depicted the rule as a <a href="http://en.wikipedia.org/wiki/Black_box">black box</a>.</p>

<p>One way<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> of thinking about <strong>black boxes</strong> is that they are a de facto special case of one-way functions: by convention, they only compute results in one direction; and since their internals are unknown, reversing this process—i.e., working out what the <em>input</em> must have been for a given <em>output</em>–is, in the best case scenario, really a challenge of deducing the inner workings of the box.</p>

<p>I think you can also think of a black box as a kind of “shifted” one-way function. Consider my earlier multiplication example: if we have a function <em>y = 3x</em>, then the <em>forward</em> case (multiplication) takes a value for <em>x</em> as input and produces a value for <em>y</em>, while the <em>reverse</em> case (division) takes a value for <em>y</em> as “output” and <em>deduces</em> a value for <em>x</em>. What is <em>fixed</em> in this example is the function itself.</p>

<p>Remember that in the case of a black box, we don’t know what the function is. What we do know is what both the inputs <em>and</em> the outputs are given our firsthand experience. So we could reframe our puzzle-solving problem as a one-way function where the “input” is actually itself a <em>function</em> (or “rule”, or “law”), and the “output” is a set of known results from applying this function to a known set of inputs. In this case, it is the <em>inputs and outputs</em>–our observations—that are fixed.</p>

<figure><img src="/images/shifted_one_way_function.png" alt="A shifted one-way function"><figcaption>A shifted one-way function</figcaption></figure>

<p>And we’re now back to pattern recognition. What I’ve just described is a shifted one-way function in the same way that Zendo is: the inputs are fixed, and outputs may be observed, but the function itself is unknown. Furthermore, while it is easy to “verify” that a theoretical function does indeed produce the observed outputs for the known, fixed set of inputs, going the other way is near impossible—in the same way that there is no right answer to a pattern recognition problem.</p>

<h2 id="the_sherlock_tendency_or_humans_and_overeager_deduction_6">The Sherlock tendency, or: humans and overeager deduction</h2>

<p>Have you ever noticed that in detective stories, when the brilliant detective protagonist finally cracks the case, he generally reveals the full narrative of what happened to a room full of mesmerized listeners? In this narrative, he paints a vivid picture of how the villain prepared, all of the meticulous steps he took to avoid detection, and all of the little mistakes he made leaving clues that ultimately led the detective to expose him.</p>

<p>Here’s why these stories, though I generally quite like them as entertainment, nonetheless fall short for me in terms of logical satisfaction. They are illustrations of what I will call the “Sherlock tendency”, which is this: as human beings, <strong>once we have identified a <em>plausible explanation</em> for some event, we think we have uncovered the truth</strong>.</p>

<figure><img src="/images/sherlock_tendency.png" alt="The Sherlock tendency"><figcaption>The Sherlock tendency</figcaption></figure>

<p>In the abstract, this is not any different from the “overeager deduction” I accused my friend of in Zendo. It is also the same as observing a sequence such as <em>1, 2, 4</em> and feeling certain at having recognized the underlying pattern.</p>

<p>This is all a <em>plausible explanation</em> really is—a proposal for a function which, when applied to the known, fixed inputs of a situation, is consistent with the observed outputs.</p>

<p>Let me try rewording that. Sometimes, we know certain things that happened at one time, and we also know things that happened at a later time; but we aren’t sure what happened in between.</p>

<figure><img src="/images/unknown_events.png" alt="Unknown events"><figcaption>Unknown events</figcaption></figure>

<p>Any murder mystery is an example of this. The victim was alive at one point; later he was discovered dead. The <em>mystery</em> is what happened to him.</p>

<p>A plausible explanation is an attempt to solve the mystery by proposing what the unknown events above <em>might have been</em> while remaining consistent with the events that <em>did</em> happen. This is <strong>clearly not the same as a certainty</strong>. And yet I seem to observe it over and over again, in practically every aspect of the world we live in: history, economics, politics, etc. As long as we can construct a narrative which is <em>consistent</em> with the experiences of our lives and the information we believe we have about the past, we feel justified in subscribing to all that narrative implies.</p>

<p>It’s an easy trap to fall into, because when an explanation is <em>inconsistent</em> with what we know, we can generally rule it out. I guess our natural instinct is to therefore run with consistency when we find it.</p>

<h2 id="why_are_we_like_this_7">Why are we like this?</h2>

<p>Not that it particularly matters, but I do have a hypothesis as to why we humans tend to think in this way.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup></p>

<p>In the very beginning of my explanation of one-way functions, I mentioned that they are hard to solve in one direction. This is fundamentally where the term comes from. And so when we think of the mystery of life as a one-way function, where we know what we’ve experienced and we are compelled to make sense of it, we find ourselves in a predicament. It is <em>very hard</em> to solve this problem. In fact, it may be impossible. So our brains aren’t up to the task.</p>

<p>And yet there is a tremendous advantage to understanding the world—both practically and emotionally. Practically speaking, we’re better able to predict and manipulate our environment when we understand its rules—so a greater capacity for understanding is an advantage. I also think we’re biologically hard-wired to feel rewarded or even euphoric whenever we’re able to solve difficult mental problems, for just this reason. It’s a kind of positive reinforcement, encouraging us to pursue even deeper understanding. (It’s one of the reasons I believe humanity has advanced so far in science and technology.) And so emotionally, I think it makes sense for humans to crave this experience: of figuring things out, of “solving” the mysteries of this world and of our lives.</p>

<figure><img src="/images/eureka.jpg" alt="Eureka!"><figcaption>Eureka!</figcaption></figure>

<h3 id="heuristics_in_software_8">Heuristics in software</h3>

<p>In computer science (and other fields as well) there are classes of very hard problems that cannot—at least <a href="http://www.claymath.org/millennium/P_vs_NP/">not yet</a>–be solved efficiently. One such class of problems is known as <a href="http://en.wikipedia.org/wiki/Np_complete">NP Complete</a>. The <em>NP</em> stands for <em>non-polynomial</em> (time), which basically means that these problems take so long to solve, the time required—as a function of the size of the input—cannot even be expressed by a polynomial expression (e.g., <em>t = n<sup>2</sup></em>).</p>

<p>One of the easier-to-explain<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup> examples of an NP Complete problem is a famous one known as the <a href="http://en.wikipedia.org/wiki/Knapsack_problem">Knapsack Problem</a>, which is this: given some container of finite capacity and a set of items with differing weights (or sizes) and values, find the optimal assortment of items that can be stored in the container.</p>

<figure><img src="/images/knapsack.png" alt="The so-called Knapsack Problem"><figcaption>The so-called Knapsack Problem</figcaption></figure>

<p>I happen to have a bit of firsthand experience with this problem, believe it or not, because at <a href="http://www.cardpool.com/buy-gift-cards">Cardpool</a> I recently implemented a feature that allows customers to specify a total card value they’d like to purchase and then automatically populates their cart from available inventory<sup id="fnref:6"><a href="#fn:6" rel="footnote">6</a></sup>. This is essentially a special case of the knapsack problem where every item’s “weight” happens to also be its value (in fact, internally we still refer to the feature as the “knapsack” feature).</p>

<p>Why do I bring this up? Well, in building this functionality, I was already aware that it’s really an NP problem. Therefore I knew it wouldn’t be realistic to try to solve with 100% accuracy or correctness; taking on a famously hard computer science problem for a simple convenience feature on a retail website would be a bit overkill. Instead, what we software developers do in situations like this is figure out <a href="http://en.wikipedia.org/wiki/Heuristic">heuristics</a>, or rough solutions that are <em>good enough</em> for practical use.</p>

<p>That’s what I did. I wrote a very basic algorithm—which is absolutely <em>not</em> a complete or strictly “correct” solution—and from my tests, sampling thousands of randomized carts, I found that it generally filled them to about 94% of the desired total value. My team and I agreed that this was good enough, and we moved on.</p>

<h3 id="heuristics_in_the_brain_9">Heuristics in the brain</h3>

<p>This is <strong>what we all do</strong>. This is how our brains work. In this world, full of so many competing ideas and possible explanations for the experiences we have, it is not feasible to comprehensively consider every possibility, with all of its nuances, any more than it is possible to efficiently solve an NP Complete problem. There are just too many ideas and not enough time.</p>

<figure><img src="/images/too_many_ideas.jpg" alt="Too many ideas"><figcaption>Too many ideas</figcaption></figure>

<p>So we exercise our internal <em>heuristics</em>, however we may have formed them over our lifetimes—forged by some mysterious blend of instinct, intuition, education, and so on—and we narrow down the options that our brains subconsciously deem worthy of consideration. The more we refine this ability, the more quickly we’re able to arrive at a final decision; this in turn gives us the emotional reward we’re after and propels us forward.</p>

<figure><img src="/images/just_one_idea.jpg" alt="Just one idea"><figcaption>Just one idea</figcaption></figure>

<p>Some of us are able to do this quite quickly, which can be advantageous even when it doesn’t lead to the truth, or to a “correct” result. We get away with it, I believe, because most of the time this strategy leads us to an understanding that is <em>good enough</em>–just like my knapsack algorithm was good enough, or like Newtownian physics was good enough until Einstein came along, or how if you pick any sufficiently controversial topic chances are you’ll be able to find <a href="http://intelligencesquaredus.org/debates">intelligent, well-reasoned arguments on either side</a>–because the truth is complicated, and it’s not possible for our brains to weigh every available piece of evidence and arrive at complete <em>certainty</em> with respect to such issues (that’s why they’re controversial). They are <em>really tough</em> one-way functions; the best debaters among us simply have the best heuristics, albeit ones that could well have led them in opposite directions.</p>

<h2 id="conclusion_10">Conclusion</h2>

<p>I think it’s important to realize that, at a very fundamental level, we actually <em>know</em> very little. The views we have adopted throughout our lives are informed by plenty of experience, sure; but there is so much universe out there, and our experience covers a relatively miniscule portion it. Our brains adapted to this early in our history, and as a species we developed a knack for using <em>heuristics</em> to form a <em>good enough</em> understanding of the world, so as not to end up paralyzed in deep contemplation our entire lives.</p>

<p>Of course I’m speculating a bit here! But can you blame me? I am after all saying that some form of speculation is all that any of us <em>ever</em> does.</p>

<p>I’ll leave you with one final analogy. Have you ever played Sudoku? It’s a great game, though it can be rather maddening when it’s too hard (my wife got me a book of <a href="http://www.amazon.com/Absolutely-Nasty-Sudoku-Official-Puzzle/dp/1402743963"><em>Nasty Sudoku</em></a> and it kills me). Have you ever had that <em>sinking feeling</em> when you’re most of the way through a Sudoku puzzle and suddenly you realize you’ve hit a contradition—there must have been a mistake (probably on your part)?</p>

<figure><img src="/images/sudoku.jpg" alt="Sudoku"><figcaption>Sudoku</figcaption></figure>

<p>This can be very easy to miss when it happens, especially if it occurs early in the puzzle. With so much unknown, a slip-up or illogical move may well not result in any obvious contradictions.</p>

<p>Now think of life as a Sudoku puzzle, but obviously much larger—with a grid extending as far as the eye can see in any direction: hundreds, thousands, millions of squares. You’re <em>never</em> going to fill in the whole grid; that would be tantamount to fully understanding the entire universe. But you’ll still make gradual progress, coming to understand more and more with age. However, you’ll also make mistakes once in a while, even if you’re good; and these mistakes will eventually lead to <em>more</em> mistakes, as happens in Sudoku. If you’re honest with yourself, you’ll therefore have to accept two things: that some of the grid you’ve already filled in is wrong (though you hope it’s a small fraction), and thus if you ever compare your grid to someone else’s and notice a discrepancy, you must be open to the possibility that theirs could be right.</p>

<p>And so the next time someone insists to me that Steorn cannot <em>possibly</em> have achieved overunity, or my friend claims to have <em>immediately</em> identified a rule in Zendo, or I see a detective movie with a resolution that neatly ties up all the details of the crime, I will remain skeptical. The universe is a one-way function; and while it may be easy for us to recognize when ideas are <em>plausible</em>, it is much, much harder to ever find the truth.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn:1">
<p>Ironically, with Steorn, I’d argue that <em>disbelief</em> is the default attitude and therefore those who dismiss the company outright are not really skeptics. Rather, those like myself who disagree (or at least did originally) that the company can be <em>immediately dismissed</em> are the skeptical ones—i.e., the ones skeptical of others’ certainty. <a href="#fnref:1" rev="footnote">↩</a></p>
</li>
<li id="fn:2">
<p>To be clear: my friend believed that he understood the master <em>personally</em> so well that he had a strong intuitive sense of the sort of rules he would think of. I remain skeptical. <a href="#fnref:2" rev="footnote">↩</a></p>
</li>
<li id="fn:3">
<p>No pun intended—I swear! <a href="#fnref:3" rev="footnote">↩</a></p>
</li>
<li id="fn:4">
<p>Notice that this hypothesis is itself a demonstration of the Sherlock tendency! Recursion, anyone? <a href="#fnref:4" rev="footnote">↩</a></p>
</li>
<li id="fn:5">
<p>By which I mean, the only example I know of off the top of my head besides <a href="http://en.wikipedia.org/wiki/Traveling_salesman_problem">Traveling Salesman</a>. <a href="#fnref:5" rev="footnote">↩</a></p>
</li>
<li id="fn:6">
<p>If you’d like to see this feature in action, <a href="http://www.cardpool.com/buy/home-depot-gift-cards">try using the “Bulk Purchase” button on Cardpool’s Home Depot page</a> and searching for, say, $2000 of cards. <a href="#fnref:6" rev="footnote">↩</a></p>
</li>
</ol>
</div>]]></description><pubDate>Wed, 3 Oct 2012 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/universe-is-a-one-way-function.html</guid></item><item><title>Cannibalizing yourself on purpose</title><link>http://www.philosopherdeveloper.com/posts/cannibalizing-yourself-on-purpose.html</link><description><![CDATA[<p>I read an article in the New York Times recently entitled <a href="http://www.nytimes.com/2012/09/22/opinion/nocera-has-apple-peaked.html">Has Apple Peaked?</a> and found myself nodding my head to a lot of the author’s points. The basic premise of the article was this: <em>maybe</em> Apple has peaked, and maybe it isn’t because Steve Jobs has passed away but rather because, as a company on top of the world, they now have everything to lose and can no longer take big risks.</p>

<p>I think there’s something to this, and I’d add another source of inertia for consideration: <strong>hubris</strong> (big surprise to those of you familiar with my general dislike for Apple, I’m sure!). At Apple’s scale, given the massive success they’ve enjoyed over the past several years, I have no doubt that the company’s sense of self-importance is extraordinarily high. Which is obviously justified to a significant degree. But one common observation I have about human nature—and I am increasingly convinced that it applies to businesses the same way it applies to individuals—is that it is very easy to pat yourself on the back for a job well done and claim more credit for your success than you <em>really</em> deserve. Put another way: it can be very easy to miss what an important role <em>luck</em> has played in your life, and thus to take full credit for your good fortune.</p>

<p>Which means that if you’re a company like Apple, you start to get complacent. You watch every product you release hit record-breaking sales, you see your competitors struggling to gain any kind of momentum, you notice the lines stretching for blocks outside every one of your retail stores, and… you start to relax. You think, <em>no one can touch us right now</em>. You feel invincible. You take for granted that everything you do is ground-breaking. Of course it is—how could it not be? You’re Apple!</p>

<p>But we’ve seen this before. Isn’t that how Microsoft felt for much of the past couple decades? And IBM before them? Now Microsoft, despite being a huge and profitable company, is nonetheless considered an underdog in some respects. And whether or not they see themselves that way, I guarantee they <em>feel</em> the pressure of public perception weighing on them. And so for the first time in a long time, Microsoft is now the one taking a big risk—with Windows 8. And you see Nokia in a similar position, taking a big risk with their Lumia phones now that their North American presence has eroded.</p>

<p>All of this has got me thinking: is this the inevitable trajectory of a successful company, or is there a way to mitigate this pattern of risk-taking followed by complacency?</p>

<p>An idea I’ve had for some time now is that of <strong>deliberate self-cannibalization as a strategy</strong>. I wonder if this is an established concept and one that many businesses have tried. Perhaps it’s an age-old idea that was debunked long ago; I don’t know. But the basic concept is this: if you’re Apple today, or Microsoft ten years ago, why not <strong>become your own competitor</strong>, and develop products that take on your existing ones?</p>

<p>Here’s my thinking. While I can completely understand that in a perfect world (for your company), your product would be perfect and gain 100% market share and nobody else could ever chip away at that, you <em>know</em> that will never be true. In fact, the bigger and more dominant you are, the more motivated emerging young entrepreneurs will be to take you on and, if they’re lucky, bring you down. So competition is a given.</p>

<p>The traditional approach for dealing with this seems to be, as far as I can tell, taking one of two paths:</p>

<ol>
<li>
<strong>Litigation</strong>: sue, or threaten to sue, any up-and-coming players and overpower them with your massive legal team before they’re big enough to stand a chance in court.</li>

<li>
<strong>Acquisition</strong>: just buy them up so you can control what they do.</li>
</ol><p>In either case, the sad reality is that it rarely seems the larger company’s intention is actually to leverage any of the smaller company’s innovation. I’ve only ever seen litigation used as a means to protect existing interests. (This is opposed to, say, a company defending a legitimately innovative idea that they still need time to develop before copycats with deeper pockets can come along and beat them to market. I’ve seriously never heard of that, at least in software.) And nine times out of ten<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, it seems acquisition is followed by either total dissolution of the acquired company (<em>Whew! Defused that bomb!</em>) or something spectacularly boring, like integration of the purchased product into the parent’s larger product suite.</p>

<p>Now consider what I’m suggesting as an alternative. I don’t want to pick exclusively on Apple and Microsoft, so let’s talk about somebody else: Google.</p>

<p>Let’s say I’m Google. I have this massively profitable product: AdWords, which relies primarily on my search engine. Then there are a number of other products that are considered core products to my company: Android, YouTube, Gmail, Google Maps, Google+ (I don’t know, I’m just giving examples—let’s say that’s a realistic list). Maybe they’re not all making money, but they’re all major players in their respective markets, all of which are either already huge or growing, or at least have great potential.</p>

<p>What else do I have? Some 30,000 employees, including a significant share of the very best engineers in the world. Also, <em>millions</em> of man hours of hard-earned knowledge and understanding about the types of products we make, the technical challenges associated with them, the needs and wants of the people who use them, and the unspoken rules and tribal knowledge of the industry we’re a part of. Oh yeah, and billions of dollars in cash to fund whatever crazy ideas I want.</p>

<p>These are all things any startup or new competitor is not going to have—at least not to the extent that I do. So why not assemble a new team within Google, consisting of employees who have proven their value in any number of ways and are itching to work on something new or otherwise break out a bit from the existing structure of the company, and ask them to work on… a totally different take on search? Or a completely new format for sharing video content? Or any number of other products that <strong>I know are going to come along anyway, and so I might as well build them myself</strong>?</p>

<p>It seems to me the traditional thinking here is that this would be bad because it would eat into existing business. But to me, turning a blind eye to the <strike>possibility</strike> inevitability that someone else is going to come after my core business—aggressively—is delusional. And expecting that just because I’m the best at what I do now, no one else will ever be able to beat me at my own game… well, that strikes me as wishful thinking.</p>

<p>Of course, I’m not suggesting that it makes sense to do this in all cases, nor that it should necessarily be one of your biggest investments if you’re a large company with many successful products. My intuitive feeling is that something like what I’m describing would make the most sense framed in the following way: whatever you are most fearful of, <strong>whatever you see as the biggest potential threat to your business: <em>build it yourself</em>.</strong></p>

<p>I can’t remember where, but I recently read an article suggesting that Google’s greatest fear right now is Amazon. The author’s reasoning was that Google makes the majority of their revenue through advertising on the kind of searches that lead directly to purchases; i.e., Google’s most profitable searches are for things like shoes and handbags and laptops and tablets, because those are the ones that allow them to display sponsored links to retailers who directly benefit from clicks and thus are willing to pay the most. Which means, basically, that Google relies on users searching through Google for things that they <em>could</em> be searching for on <em>Amazon</em>. Which in turn means that Amazon stands to gain quite a lot by improving their search capabilities and getting aggressive about taking on Google in that arena.</p>

<p>I actually don’t know whether or not this is true (even if it is I’m sure it’s only half the picture), but let’s assume for argument’s sake that it is. In that case, then what I would suggest is that Google start asking themselves questions like: <em>What is it that we’re afraid Amazon might make?</em> And: <em>What would that product look like?</em> And finally: <em>How can we build it before them?</em></p>

<p>Lest you think I’m just talking about Google Shopping—a product that has already existed for quite some time—let me clarify something. I actually think one of the most important aspects of this idea of self-cannibalization is that it should <em>not</em> be treated as a new component of an existing product suite or brand. Remember, my suggestion is to build the thing you’re <em>afraid</em> of. And Google is certainly not afraid of a product called “Google Shopping” (or “Froogle”, or whatever else it used to be called).</p>

<p>So I am talking about creating an entirely new brand, for one thing, and even possibly a whole new company. In fact I’d expect that distancing this new venture publicly from the original company as much as possible would be wise. But the crucial differentiator from any other startup would be that, internally, this project would have access to the same resources, the same engineering know-how, the same marketing muscle, and—perhaps most importantly—the same <em>data</em> as its parent. And it would be run by a team with the incredible advantage of knowing exactly what their “competitor” feared.</p>

<p>Meanwhile, <em>of course</em> you’d still be working as hard as ever on your core product, the one that’s now under friendly fire—just like you would be if an <em>actual</em> competitor had come on the scene and started chipping away at you. But this way, there are two equally good potential outcomes. One is that the core product comes out victorious, and your new internal “competitor” product is either scrapped or consumed for its most worthwhile ideas. The other is that the competitor actually does start eating away at the main business, in which case:</p>

<ul>
<li>That’s exactly what you feared, right? So, that’s bad? Except:</li>

<li>The revenue is actually coming to you anyway. So maybe it’s OK. Plus:</li>

<li>Since both products are yours, you don’t need to become embroiled in a price war. <strong>And</strong>:</li>

<li>If a legitimate outside competitor does come along, now they’ve got to beat <em>two</em> major players—who are working together!–instead of one.</li>
</ul><p>OK, so now that I’ve written at length about this idea, I acknowledge that there are some obvious problems with it. (And probably a lot more problems than I can even think of.) The most obvious is simply that what I’m talking about is, in theory, hugely inefficient. I’m sure there aren’t a lot of executives out there who’d be thrilled at the idea of basically throwing twice the resources at the same problem in anticipation of a nonexistent competitor.</p>

<p>But I see the issue a bit differently. In my experience, doubling the resources invested in a product falls far short of doubling the output (ever heard of the <a href="http://www.amazon.com/The-Mythical-Man-Month-Engineering-Anniversary/dp/0201835959">Mythical Man Month</a>?); and so the perceived “inefficiency” of duplicating effort on a separate project is likely to be seriously exaggerated. In fact, it could very well be more efficient to create a new <a href="http://www.zurb.com/word/two-pizza-team">two-pizza team</a> and put them on a new project, where each individual can make an enormous contribution, than it would be to assign those same individuals to an existing 40-person project, where the communication and coordination overhead of managing such a large team would reduce the proportional effectiveness of each individual and weigh the whole thing down.</p>

<p>Another objection I could easily see to the self-cannibalization idea is that it would dilute the brand and/or fragment the company in a harmful way. This seems like a legitimate danger to me, and one that I believe it would take great care and good judgment to defend against. On some level I suppose a company’s vulnerability to this threat depends on culture, morale, and public perception. But I’d still argue that, in some cases, it’s a challenge worth tackling. Especially when the alternative is resting on your laurels while others are plotting ways to disrupt your business.</p>

<p>Obviously I am no expert on any of this. It’s just an idea. I will close, though, by making just a few sweeping generalizations.</p>

<p>Innovation requires risk. Dominance in technology relies <em>at least in part</em> on innovation, which means that you cannot be a technology company and not expect to take risks. If you are successful, and you want to continue to be successful, but you are no longer willing to take risks, it is only natural that others <em>will</em> be; and for some non-zero fraction of them, those risks will likely pay off. So in the end, I think what I’ve described as “self-cannibalization” is really just smart risk management, though perhaps I could have done a better job defining it.</p>

<p>Anyway, it’s a thought.</p>
<div class="footnotes">
<hr>
<ol><li id="fn:1">
<p>I did not research this figure. <a href="#fnref:1" rev="footnote">↩</a></p>
</li></ol>
</div>]]></description><pubDate>Mon, 24 Sep 2012 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/cannibalizing-yourself-on-purpose.html</guid></item><item><title>Brushing up on C.S. - Part 1: Algorithmic Complexity</title><link>http://www.philosopherdeveloper.com/posts/brushing-up-on-cs-part-1-algorithmic-complexity.html</link><description><![CDATA[<h1 id="preamble_1">Preamble</h1>

<p>As I’m sure plenty of you already know (the title of this blog is a bit of a giveaway), I was a <strong>philosophy</strong> major in college. Which means I was <em>not</em> a C.S. major. But that’s not the full extent of it: I didn’t <em>minor</em> in C.S., either; I actually took <em>absolutely no computer sciences courses at all</em> in college.</p>

<p>I did recently receive an M.S. in software engineering from <a href="http://www.cmu.edu/silicon-valley/">Carnegie Mellon</a>; but the courses in that program were higher-level in nature: software architecture, process management, software metrics, entrepreneurship—that sort of thing. And so I’ve still never really had an academic foundation for a lot of the more theoretical stuff that those with bachelor’s degrees in computer science have.</p>

<p>To clarify: I <em>do</em> know a decent amount of C.S. stuff in practice, because:</p>

<ul>
<li>I worked for two years at an algorithmic trading company, where performance was a key concern (use of optimal data structures was critical) and the software was highly concurrent (so I got plenty of hands-on experience with things like synchronization, mutexes, semaphores, etc.)</li>

<li>I am a huge nerd who spends way too much time reading about <a href="http://en.wikipedia.org/wiki/Skip_list">skip lists</a> and <a href="http://en.wikipedia.org/wiki/Red_black_tree">red-black trees</a> and all that good stuff on Wikipedia</li>
</ul><p>Anyway, all this is my long-winded way of introducing a little series of blog posts I’m going to be doing, starting with this one. The basic idea behind it should already be obvious: I’m going to “brush up” on (in some cases, learn entirely from scratch) some of the fun theoretical stuff that I missed by never going through a college C.S. program.</p>

<p>Those of you already well-versed with theoretical C.S. stuff will probably not be all that intrigued by this or the next few posts. Then again, maybe you will. My goal is actually two-fold here:</p>

<ol>
<li>Obviously, to add to my own knowledge and study some of the things that fascinate me more in depth</li>

<li>To do my best to explain these concepts in a straightforward and easily comprehensible way, so that even someone without a C.S. background can understand them (at least insofar as it’s feasible—I will readily admit some of this stuff may end up being too tricky for me to explain without requiring some lower level knowledge on the part of the reader)</li>
</ol><p>OK, now that I’ve written about five too many paragraphs <em>introducing</em> this series (not off to a good start!), let’s go ahead and dive in.</p>

<h1 id="part_1_algorithmic_complexity_2">Part 1: Algorithmic Complexity</h1>

<p>So originally I was thinking I’d start with some sorting algorithms. I’m excited about that topic, because it’s honestly one of the things that got me really psyched about computer programming when I first started (which also means it probably isn’t the best topic for the first goal I mentioned above, because a lot of this stuff I’ve known for a while). I remember when I first started learning several years ago, reading through countless Wikipedia articles about <a href="http://en.wikipedia.org/wiki/Sorting_algorithm">all the different sorting algorithms</a> that have been devised over the years and being totally obsessed with it. I just thought it was the coolest thing ever.</p>

<p>But upon thinking about it for a bit, I realized I’d be getting ahead of myself by starting there. If you visit the Wikipedia page I just linked to, you’ll see a big table listing the names of a bunch of famous algorithms, with columns labeled “Best”, “Average”, and “Worst” and containing values like <em>n<sup>2</sup></em> and <em>n log n</em>. I noticed that table, and it occurred to me that most people have no idea what those things mean. (And to be honest with you, I’ve met a lot of <em>developers</em> who don’t fully understand what they mean either. Most have a rough sense, but often developers think they get it when in fact they are mistaken about a few things, which I’ll get to.) And so the best place for me to start, if I want to eventually get to sorting algorithms, is a concept called <strong>algorithmic complexity</strong>.</p>

<h3 id="the_basic_gist_3">The Basic Gist</h3>

<p>I personally find most academic terms like “algorithmic complexity” to be vaguely pretentious<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, so I’m going to present the idea as much in plain English as I can. The whole point of this concept is to explain how well an algorithm—essentially, any software procedure, or even more simply a set of instructions—will perform, i.e., <strong>how fast it runs</strong>. But that’s not the whole picture. Actually, how “fast” an algorithm runs is not a specific enough question; the real issue is how fast it runs <em>for a given set of input</em>.</p>

<p>(I can already see the flags going up in my more technical readers heads: “That is not an accurate way of explaning algorithmic complexity!” Hold your horses, guys. I’m getting there.)</p>

<p>It’s pretty easy to explain the distinction I just made. Imagine if someone were to ask you, “How fast can you paint a house?” Your first obvious response would almost certainly <em>not</em> be: “About a week.” How could you give an answer without knowing more context about what the person is asking? You’d need to know: How <em>large</em> of a house? What <em>kind</em> of house? Under what conditions? And so on.</p>

<p>But there’s another, more important distinction between the concepts of <em>speed</em> and <em>complexity</em>. And this is the part that a lot of developers don’t actually understand (though I’m sure all the developers reading this do!). To describe it, I’ll give another (absurd) analogy.</p>

<h3 id="choosing_a_gym_membership_4">Choosing a Gym Membership</h3>

<p>Let’s say you decide to join a gym, and you have two choices. Gym A will charge you $100 every year that you have a membership with them. Gym B, on the other hand, charges a one-time fee of $1000 for joining. After that, though, they charge no recurring fees.</p>

<p>For the sake of illustration, let’s say that whichever gym you choose, you will be a member with them for life. Put aside for now the fact that that isn’t very realistic. My question to you is: which should you choose, given that you must choose one?</p>

<p>It isn’t a hard question, really. Most of us have dealt with some decision like this at some point in our lives; or anyway, we can think logically enough to see that a one-time cost of $1000 is probably better than paying $100 <em>every year</em>, as the latter would likely amount to more than $1000 over the course of a lifetime.</p>

<p>To prove this intuition, let’s suppose you have 25 more years to live. Then:</p>

<p>$100 × 25 years = $2,500</p>

<p>You would ultimately pay Gym A more than twice as much as you’d pay Gym B in this case. Pretty bad. But what if you had <em>50</em> more years to live? Then with Gym A you’d pay $5,000, more than <em>four times</em> as much as you’d pay with Gym B.</p>

<p>We’re now honing in on what algorithmic complexity is really about. It is intended as a way of measuring <strong>the cost of an algorithm relative to input size</strong>. In the gym example, we could think of “Choose Gym A” or “Choose Gym B” as two separate algorithms, where the input size is the number of years you have a membership with either gym.</p>

<p>In the case of Gym A, doubling the number of years doubles the cost. So in terms of algorithmic complexity, we would say this is <em>O(n)</em><sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>, which I read as “order of <em>n</em>” (the <em>n</em> represents whatever value you use to define input size—in this case, the number of years).</p>

<p>In the case of Gym B, doubling the number of years does what? Has no effect, actually. The cost is $1,000 regardless of whether you’re with the gym for 1 year or 100 years. And so we would describe this “algorithm’s” complexity as <em>O(1)</em>. Notice there is no <em>n</em> there, because the input size in this case does not impact the cost of the algorithm at all.</p>

<h3 id="complexity_versus_suitability_5">Complexity Versus Suitability</h3>

<p>Now, I’ve met plenty of engineers who mistake this to mean that <em>O(1)</em> is “better” or “faster” than <em>O(n)</em>. But that’s not quite right. $1000 is a lot of money. Suppose I took away the restriction that you had to stay with either Gym A or Gym B for the rest of your life. If you were only to keep your membership for a few years, then Gym A would end up costing you <em>less</em> than $1000; and suddenly the <em>O(n)</em> option would be a smarter choice than the <em>O(1)</em> one.</p>

<p>And so there is often a judgment call involved in picking the right algorithm for a particular scenario. In the world of sorting algorithms, for instance (the topic I intend to write about next), you will often see cases of “hybrid” algorithms which start with some <em>O(n log n)</em> algorithm (like <a href="http://en.wikipedia.org/wiki/Quicksort">Quicksort</a>) for large sets of input data, but then convert to a <em>O(n<sup>2</sup>)</em> algorithm (like <a href="http://en.wikipedia.org/wiki/Insertion_sort">Insertion sort</a>) when the input size is small. In other words: preferring the cost structure of something like Gym B in general, but being open to joining something like Gym A if it’s only for a short time.</p>

<h3 id="one_last_example_6">One Last Example</h3>

<p>I should offer one more example of complexity, since I’ve only hit on two fairly easy-to-understand cases so far–<em>O(1)</em> and <em>O(n)</em>. For this example, I will refer to a common method people use to greet one another in groups.</p>

<p>Let’s say Jack and Jill meet for the first time.</p>

<p>Here’s one way it could go down: Jack says “Hi, I’m Jack,” to which Jill responds, “Hello, I’m Jill,” and they shake hands.</p>

<p>Two people, two introductions (Jack introducing himself to Jill and vice versa). Seems reasonably efficient, right?</p>

<p>Let’s add two more people to the mix: Alice and Bob. Below is a quick list of the introductions that would occur in this group of four, following the same sort of greetings as above:</p>

<ol>
<li>Jack-Jill</li>

<li>Jack-Alice</li>

<li>Jack-Bob</li>

<li>Jill-Jack</li>

<li>Jill-Alice</li>

<li>Jill-Bob</li>

<li>Alice-Jack</li>

<li>Alice-Jill</li>

<li>Alice-Bob</li>

<li>Bob-Jack</li>

<li>Bob-Jill</li>

<li>Bob-Alice</li>
</ol><p>Whoa! We just went from two introductions to twelve! Clearly this method of greeting people would not be sustainable if the number of people grew much larger. (And yet, the Owambo people in Namibia greet one another in precisly this way—and to be honest, I quite like it. But that is a <em>completely</em> different topic.)</p>

<p>So, clearly this situation is different from the case of Gym A from my earlier example. Whereas with Gym A, the cost of membership grew <em>linearly</em> (in a straight line) over time, the number of greetings above basically explodes out of control if you add many more people to the setting. This is an example of an <em>O(n<sup>2</sup>)</em> algorithm—one in which the performance cost of the procedure in question grows <em>exponentially</em> with input size.</p>

<p>It probably isn’t the best example I could have given, as it’s not 100% obvious that the exponent should be 2 (4 squared is 16, not 12). If you want an explanation, I’ll provide it in a footnote<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>.</p>

<p>Anyway, hopefully now you have a sense of what algorithmic complexity is about. If you only have a rough idea but don’t feel like you totally understand it yet, that’s OK; I will do my best to give better examples and provide better explanations as I move forward in this blog series.</p>

<p>And if you found this material mind-numbingly boring: don’t worry, I will most likely break up the series with posts about other topics from time to time as well.</p>
<div class="footnotes">
<hr>
<ol>
<li id="fn:1">
<p>Yeah, I don’t totally know why. To be fair, I find “industry” terms like <em>scalability</em> to be equally pretentious, for similarly inexplicable reasons. <a href="#fnref:1" rev="footnote">↩</a></p>
</li>
<li id="fn:2">
<p>This way of describing complexity is called <a href="http://en.wikipedia.org/wiki/Big_o_notation">Big O notation</a>, and it’s probably one of the most common interview topics that I can think of for software engineers. <a href="#fnref:2" rev="footnote">↩</a></p>
</li>
<li id="fn:3">
<p>Unless I’m mistaken, the greeting procedure really is O(n<sup>2</sup>). The reason is this. For every person you introduce into the group, that person has to greet everyone already in the group. So if the group consists of n people, and you add another person, right there that’s n more introductions. But <em>in addition</em>, every person in the group also has to greet the new person; so that’s <em>another</em> n more introductions. In total, the number of introductions will always be n<sup>2</sup> (every person greeting every other person), minus n since you don’t greet yourself. So in the example I gave, 4 people made 12 introductions, which is 16 (4 squared) minus 4 since Jack did not introduce himself to Jack, etc. <a href="#fnref:3" rev="footnote">↩</a></p>
</li>
</ol>
</div>]]></description><pubDate>Sat, 15 Sep 2012 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/brushing-up-on-cs-part-1-algorithmic-complexity.html</guid></item><item><title>A magical optimization of the += operator with strings</title><link>http://www.philosopherdeveloper.com/posts/magical-optimization-of-the-%2B%3D-operator-with-strings.html</link><description><![CDATA[<p>Today I felt like writing something more low-level than I’ve written in a while… and since C# is about the lowest I go (yeah, pretty sad—I haven’t really earned my beard yet), that will be my language of choice for this post.</p>

<p>But we start with JavaScript, actually. A couple of months ago, shortly after joining <a href="http://www.cardpool.com/">Cardpool</a>–a topic <em>definitely</em> deserving of its own post, in due time—I started working on a top-secret new project. Without giving too much away (as if it really matters), I’ll just say that my work on this project involved writing a library to process a sequence of data from an input device which emulated a computer keyboard. Essentially this input sequence would ultimately be interpreted as a string; but unlike your typical scenario of taking user input from, e.g., a text field—where the string is given to you all at once—in this case the library had to <em>assemble</em> the string from bytes fed to it one-by-one.</p>

<p>In a language like Java or C# (or even Ruby), this would be totally easy, albeit unconventional. The data structure for a string is <a href="http://philosopherdeveloper.wordpress.com/2010/05/28/are-strings-really-immutable-in-net/">more or less</a> immutable in Java and C#, but both have the concept of a mutable <code>StringBuilder</code> for precisely the case where you need to construct a string by concatenating many segments. And in Ruby, strings are mutable to begin with (you use the <code>&lt;&lt;</code> operator to append to an existing string).</p>

<p>But this library I was working on was in <em>JavaScript</em>–a language that I love, but one without any specialized options for concatenating strings quickly. JavaScript strings are immutable, and there is no concept of a <code>StringBuilder</code>. If you want to concatenate many strings together, you have two options:</p>

<ul>
<li>The good ol’ <code>+=</code> operator</li>

<li>Storing the elements in an array, and then calling <code>join()</code>
</li>
</ul><p>Before bothering to profile anything, here was my guess: I figured that on small strings, the two options would be roughly equivalent. But given that strings in JavaScript are immutable, I assumed that even on modern browsers the array-based concatenation strategy would prove superior pretty much across the board. That would make sense, right?</p>

<p>To my surprise, after <a href="http://jsperf.com/concatenating-lots-of-little-strings/2">profiling the two options on a variety of browsers</a>, I found that the <code>+=</code> operator beats the pants off the array method on Chrome.</p>

<figure><img src="http://i.imgur.com/wIYN7.png" alt="The performance of += on Chrome is pretty astonishing"><figcaption>The performance of += on Chrome is pretty astonishing</figcaption></figure>

<p><em>How could this be?</em> I thought. Given an immutable data structure for strings, it seemed to me any use of <code>+</code> would necessitate the allocation of an entirely new block of memory to hold a copy of the original data plus the appended data. The only obvious alternative I could think of was to use some sort of <a href="http://en.wikipedia.org/wiki/Rope_%5C(computer_science%5C">rope</a>), which felt like a totally unwarranted compromise for a language like JavaScript given that it would make random access O(log N) instead of O(1) and would hardly ever be useful (not to mention that appends would still be O(log N), so they almost certainly still wouldn’t beat the array method).</p>

<p>Obviously the Chrome developers cooked up some crazy optimization for the <code>+=</code> operator; but what <em>was</em> it? (Incidentally, it seems that some engineers at Microsoft must have done something similar for Windows 8, since IE 10 shows a similar performance disparity between using <code>+=</code> and the array method). It got me thinking: if I were to optimize for this case—and it does make some sense, considering how <code>+=</code> is really your only option in JavaScript, or at least by far the most obvious one that JavaScript developers are likely to use—how might I do it?</p>

<p>Well, perhaps the pay-off won’t be worth my long-winded exposition thus far. But here’s what I came up with. I actually quite like it. (Though to be clear: this is really just a proof of concept, and I would almost certainly not have any use for it in any production code.)</p>

<p>The challenge, just to reiterate one last time, was to create <strong>an immutable implementation of strings optimized for very fast appends using the <code>+</code> operator</strong>. I came up with a solution in C#. Obviously the Chrome devs did not use C#–nor did the Microsoft devs, for that matter—but I’m sure they could have taken a similar approach in whatever language they used. I’m not saying they <em>did</em>–chances are their solution is much smarter than mine—just that they <em>could</em> have.</p>

<h2 id="the_basic_idea_1">The Basic Idea</h2>

<p>Here’s what I came up with. For starters, I needed to forget about what a string “is”–or anyway, what my notion of one was prior to thinking about this optimization: as a particular <em>data structure</em> comprising a contiguous sequence of characters—and focus on the <em>concept</em> of a string, which I would say is more closely related to <em>the interface it provides</em>: random access to such a sequence, along with the total length of the sequence. From these basic building blocks all other aspects of a string’s interface can be derived: iteration, substring operations, replace, search, the whole shebang. (If you think about it, you could actually implement the entire interface for, say, .NET’s <code>System.String</code> class using only an <code>IList&lt;char&gt;</code> as the backing data structure. But I’ll leave that to you as an exercise.)</p>

<p>Fine, so you’re with me so far. I’m sure most of you already knew that anyway. But what does this shift in focus give us? Essentially, it allows us to conjure <strong>an immutable <em>concept</em> with a mutable <em>data structure</em> underneath it</strong>. And this is the basis for <a href="https://gist.github.com/3471636">my <code>FastString</code> class</a>.</p>

<h2 id="the_implementation_2">The Implementation</h2>

<p>At the heart of a <code>FastString</code> object there are two parts: <code>buffer</code>, an underlying <code>StringBuilder</code> (the mutable data structure underneath), and <code>length</code>, an integer. In addition to these fields, there is the concept of <strong>buffer ownership</strong>: if a <code>FastString</code> has the same length (not to be confused with <em>capacity</em>) as its buffer, that means it is the “owner” of the buffer:</p>

<div class="highlight"><pre><span class="k">private</span> <span class="kt">bool</span> <span class="n">OwnsBuffer</span>
<span class="p">{</span>
    <span class="k">get</span> <span class="p">{</span> <span class="k">return</span> <span class="k">this</span><span class="p">.</span><span class="n">buffer</span><span class="p">.</span><span class="n">Length</span> <span class="p">==</span> <span class="k">this</span><span class="p">.</span><span class="n">length</span><span class="p">;</span> <span class="p">}</span>
<span class="p">}</span>
</pre></div>

<p>Now, the idea here is that if you use <code>+</code> to append to a <code>FastString</code>, two things can happen. If the <code>FastString</code> is the owner of its underlying buffer, that means that you can safely append directly to the buffer. This is because no other <code>FastString</code> instances can be referencing any characters past the current end of the buffer, and so the immutability of every existing instance is maintained. Then the <code>+</code> operator returns a new <code>FastString</code> instance pointing to the same buffer but with the new length. At this point, this new instance becomes the buffer’s new owner.</p>

<p>It is a bit of a strange approach, I grant you. But it is perfect for a particularly common use case: concatenating many strings in a loop:</p>

<div class="highlight"><pre><span class="n">FastString</span> <span class="n">whole</span> <span class="p">=</span> <span class="s">""</span><span class="p">;</span>
<span class="k">foreach</span> <span class="p">(</span><span class="kt">string</span> <span class="n">part</span> <span class="k">in</span> <span class="n">parts</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">whole</span> <span class="p">+=</span> <span class="n">part</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>

<p>Here, every time a new <code>FastString</code> is instantiated via the <code>+=</code> operator, the previous owner (which is essentially discarded in the above loop) cedes ownership and the new instance inherits it. Notably, this will have the same performance characteristics as using a <code>StringBuilder</code>, because, after all, that’s basically what it is doing. But the proof is in the pudding: here’s example output from a sample run concatenating 20,000 strings:</p>

<pre><code>Finished concatenating 20000 strings the 'fast' way in 2.7935 ms.
Finished concatenating 20000 strings the 'slow' way in 4832.8853 ms.
Output equal? True</code></pre>

<p>A <strong>1730x</strong> speed-up? I’d say that’s not bad! (And this would of course only increase as the number of strings increased—since the <code>FastString</code> approach should have amortized O(1) complexity versus the O(N) that <code>String</code> provides.)</p>

<p>Is this what the Chrome devs did? Like I said, I doubt it. I would actually be very curious to know what approach they used. (I’m guessing that since I don’t have much experience in lower-level languages than C#, there are probably a whole collection of tricks I would never even think of.) And if <em>you</em> can think of any other optimizations, leave a comment and let me know!</p>

<p>Anyway, as I wrote already, this is not really useful in any real-world application I can imagine. But it was a fun challenge to take on, and I hope it was interesting to read about. Also, it’s nice to write about something relatively low-level (at least compared to my usual fare) every once in a while. This is the stuff that got me into programming in the first place.</p>

<p>But that’s the topic of another, much higher-level post. Speaking of which, I should probably write soon about a couple of fairly major events in my personal and professional life:</p>

<ol>
<li>Leaving ThoughtWorks</li>

<li>Graduating from CMU</li>
</ol><p>Let that be a reminder to myself, for next time.</p>]]></description><pubDate>Sat, 25 Aug 2012 00:00:00 +0000</pubDate><guid>http://www.philosopherdeveloper.com/posts/magical-optimization-of-the-%2B%3D-operator-with-strings.html</guid></item></channel></rss>